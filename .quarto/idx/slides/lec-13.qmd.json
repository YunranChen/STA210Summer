{"title":"Feature engineering","markdown":{"yaml":{"title":"Feature engineering","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","multiplex":true,"transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto"}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 10, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n```\n\n# Welcome\n\n## Announcements\n\n::: nonincremental\n-   My Monday office hours moved to 8-9pm\n:::\n\n## Topics\n\n::: nonincremental\n-   Feature engineering with recipes\n-   Workflows to bring together models and recipes\n-   RMSE and $R^2$ for model evaluation\n-   Cross validation\n:::\n\n## Computational setup\n\n```{r}\n#| echo: true\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n# Introduction\n\n## The Office\n\n![](images/lec-13/the-office.jpeg)\n\n## Data & goal\n\n-   Data: The data come from [data.world](https://data.world/anujjain7/the-office-imdb-ratings-dataset), by way of [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-03-17/readme.md)\n\n-   Goal: Predict `imdb_rating` from other variables in the dataset\n\n```{r}\n#| echo: true\n\noffice_ratings <- read_csv(here::here(\"slides\", \"data/office_ratings.csv\"))\noffice_ratings\n```\n\n# Modeling\n\n## Train / test\n\n**Step 1:** Create an initial split:\n\n```{r}\n#| echo: true\n\nset.seed(123)\noffice_split <- initial_split(office_ratings) # prop = 3/4 by default\n```\n\n**Step 2:** Save training data\n\n```{r}\n#| echo: true\n\noffice_train <- training(office_split)\ndim(office_train)\n```\n\n**Step 3:** Save testing data\n\n```{r}\n#| echo: true\n\noffice_test  <- testing(office_split)\ndim(office_test)\n```\n\n## Training data\n\n```{r}\n#| echo: true\n\noffice_train\n```\n\n## Recap: Feature engineering\n\n-   We prefer simple models when possible, but **parsimony** does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\n\n-   Variables that go into the model and how they are represented are just as critical to success of the model\n\n-   **Feature engineering** allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)\n\n## Recap: Modeling workflow, revisited\n\n-   Create a **recipe** for feature engineering steps to be applied to the training data\n\n-   Fit the model to the training data after these steps have been applied\n\n-   Using the model estimates from the training data, predict outcomes for the test data\n\n-   Evaluate the performance of the model on the test data\n\n# Building recipes\n\n## Initiate a recipe\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2|3\"\n\noffice_rec <- recipe(\n  imdb_rating ~ .,    # formula\n  data = office_train # data for cataloguing names and types of variables\n  )\n\noffice_rec\n```\n\n## Step 1: Alter roles\n\n`title` isn't a predictor, but we might want to keep it around as an ID\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  update_role(title, new_role = \"ID\")\n\noffice_rec\n```\n\n## Step 2: Add features\n\nNew features for day of week and month\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_date(air_date, features = c(\"dow\", \"month\"))\n\noffice_rec\n```\n\n## Working with recipes {.smaller}\n\n-   When building recipes you in a pipeline, you don't get to see the effect of the recipe on your data, which can be unsettling\n-   You can take a peek at what will happen when you ultimately apply the recipe to your data at the time of fitting the model\n-   This requires two functions: `prep()` to train the recipe and `bake()` to apply it to your data\n\n. . .\n\n::: callout-note\nThis is optional, we'll show the results for demonstrative purposes.\nIt doesn't need to be part of your modeling pipeline, but I find it assuring to see the effects of the recipe steps as I build the recipe.\n:::\n\n## Step 2: Prep and bake\n\n```{r}\n#| echo: true\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) %>%\n  glimpse()\n```\n\n## Step 3: Add more features {.smaller}\n\nIdentify holidays in `air_date`, then remove `air_date`\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2,3,4,5,6\"\n\noffice_rec <- office_rec %>%\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  )\n\noffice_rec\n```\n\n## Step 3: Prep and bake {.smaller}\n\n```{r}\n#| echo: true\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) %>%\n  glimpse()\n```\n\n## Step 4: Convert numbers to factors {.smaller}\n\nConvert `season` to factor\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_num2factor(season, levels = as.character(1:9))\n\noffice_rec\n```\n\n## Step 4: Prep and bake {.smaller}\n\n```{r}\n#| echo: true\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) %>%\n  glimpse()\n```\n\n## Step 5: Make dummy variables {.smaller}\n\nConvert all nominal (categorical) predictors to factors\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_dummy(all_nominal_predictors())\n\noffice_rec\n```\n\n## Step 5: Prep and bake {.smaller}\n\n```{r}\n#| echo: true\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) %>%\n  glimpse()\n```\n\n## Step 6: Remove zero variance predictors {.smaller}\n\nRemove all predictors that contain only a single value\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_zv(all_predictors())\n\noffice_rec\n```\n\n## Step 6: Prep and bake {.smaller}\n\n```{r}\n#| echo: true\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) %>%\n  glimpse()\n```\n\n## Putting it altogether {.smaller}\n\n```{r}\n#| label: recipe-altogether\n#| echo: true\n#| results: hide\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  # make title's role ID\n  update_role(title, new_role = \"ID\") %>%\n  # extract day of week and month of air_date\n  step_date(air_date, features = c(\"dow\", \"month\")) %>%\n  # identify holidays and add indicators\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  ) %>%\n  # turn season into factor\n  step_num2factor(season, levels = as.character(1:9)) %>%\n  # make dummy variables\n  step_dummy(all_nominal_predictors()) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n```\n\n## Putting it altogether {.smaller}\n\n```{r}\n#| echo: true\n\noffice_rec\n```\n\n# Building workflows\n\n## Specify model\n\n```{r}\n#| echo: true\n\noffice_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_spec\n```\n\n## Build workflow\n\n**Workflows** bring together models and recipes so that they can be easily applied to both the training and test data.\n\n```{r}\n#| echo: true\n\noffice_wflow <- workflow() %>%\n  add_model(office_spec) %>%\n  add_recipe(office_rec)\n```\n\n<br>\n\n*See next slide for workflow...*\n\n## View workflow\n\n```{r}\n#| echo: true\n\noffice_wflow\n```\n\n## Fit model to training data {.smaller}\n\n```{r}\n#| echo: true\n\noffice_fit <- office_wflow %>%\n  fit(data = office_train)\n\ntidy(office_fit)\n```\n\n<br>\n\n. . .\n\n*So many predictors!*\n\n## Model fit summary\n\n```{r}\n#| echo: true\n\ntidy(office_fit) %>% print(n = 21)\n```\n\n# Evaluate model\n\n## Make predictions for training data\n\n```{r}\n#| echo: true\n\noffice_train_pred <- predict(office_fit, office_train) %>%\n  bind_cols(office_train %>% select(imdb_rating, title))\n\noffice_train_pred\n```\n\n## R-squared\n\nPercentage of variability in the IMDB ratings explained by the model.\n\n. . .\n\n```{r}\n#| echo: true\n\nrsq(office_train_pred, truth = imdb_rating, estimate = .pred)\n```\n\n. . .\n\n::: question\nAre models with high or low $R^2$ more preferable?\n:::\n\n## RMSE\n\nAn alternative model performance statistic: **root mean square error**.\n\n$$ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}} $$\n\n. . .\n\n```{r}\n#| label: rmse-train\n#| echo: true\n\nrmse(office_train_pred, truth = imdb_rating, estimate = .pred)\n```\n\n. . .\n\n::: question\nAre models with high or low RMSE are more preferable?\n:::\n\n## Interpreting RMSE\n\n::: question\nIs this RMSE considered low or high?\n:::\n\n```{r}\n#| ref.label: \"rmse-train\"\n#| echo: true\n```\n\n<br>\n\n. . .\n\nDepends...\n\n```{r}\n#| echo: true\n\noffice_train %>%\n  summarise(min = min(imdb_rating), max = max(imdb_rating))\n```\n\n## But, really...\n\n*who cares about predictions on **training** data?*\n\n## Make predictions for testing data\n\n```{r}\n#| echo: true\n\noffice_test_pred <- predict(office_fit, office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, title))\n\noffice_test_pred\n```\n\n## Evaluate performance for testing data\n\nRMSE of model fit to **testing** data\n\n```{r}\n#| echo: true\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n```\n\nR-sq of model fit to **testing** data\n\n```{r}\n#| echo: true\n\nrsq(office_test_pred, truth = imdb_rating, estimate = .pred)\n```\n\n## Training vs. testing\n\n```{r}\nrmse_train <- rmse(office_train_pred, truth = imdb_rating, estimate = .pred) %>%\n  pull(.estimate) %>%\n  round(3)\n\nrsq_train <- rsq(office_train_pred, truth = imdb_rating, estimate = .pred) %>%\n  pull(.estimate) %>%\n  round(3)\n\nrmse_test <- rmse(office_test_pred, truth = imdb_rating, estimate = .pred) %>%\n  pull(.estimate) %>%\n  round(3)\n\nrsq_test <- rsq(office_test_pred, truth = imdb_rating, estimate = .pred) %>%\n  pull(.estimate) %>%\n  round(3)\n```\n\n| metric    |          train |          test | comparison                    |\n|:----------|---------------:|--------------:|:------------------------------|\n| RMSE      | `r rmse_train` | `r rmse_test` | RMSE lower for training       |\n| R-squared |  `r rsq_train` |  `r rsq_test` | R-squared higher for training |\n\n## Evaluating performance on training data {.smaller}\n\n-   The training set does not have the capacity to be a good arbiter of performance.\n\n-   It is not an independent piece of information; predicting the training set can only reflect what the model already knows.\n\n-   Suppose you give a class a test, then give them the answers, then provide the same test.\n    The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-13.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Feature engineering","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","multiplex":true,"transition":"fade","slideNumber":true,"chalkboard":true}}}}