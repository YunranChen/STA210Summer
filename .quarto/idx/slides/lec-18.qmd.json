{"title":"Logistic regression","markdown":{"yaml":{"title":"Logistic regression","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto","echo":true}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 10, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n\nlibrary(countdown)\n```\n\n# Welcome\n\n## Announcements\n\n-   Schedule changes for the remainder of the semester\n\n-   Thursday office hours in my office: 213 Old Chem\n\n-   Any questions on project proposals?\n\n## Topics\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Use logistic regression model to calculate predicted odds and probabilities\n\n## Computational setup\n\n```{r}\n#| warning: false\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n# Predicting categorical outcomes\n\n## Types of outcome variables\n\n**Quantitative outcome variable**:\n\n-   Sales price of a house in Levittown, NY\n-   **Model**: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\n\n**Categorical outcone variable**:\n\n-   High risk of coronary heart disease\n-   **Model**: Probability an adult is high risk of heart disease given their age, total cholesterol, etc.\n\n## Models for categorical outcomes\n\n::: columns\n::: {.column width=\"50%\"}\n**Logistic regression**\n\n2 Outcomes\n\n1: Yes, 0: No\n:::\n\n::: {.column width=\"50%\"}\n**Multinomial logistic regression**\n\n3+ Outcomes\n\n1: Democrat, 2: Republican, 3: Independent\n:::\n:::\n\n## 2020 election forecasts\n\n![](images/lec-18/fivethirtyeight_president_nc.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight Election Forcasts](https://projects.fivethirtyeight.com/2020-election-forecast/)\n\n## NBA finals predictions\n\n![](images/lec-18/nba-predictions.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight 2019-20 NBA Predictions](https://projects.fivethirtyeight.com/2020-nba-predictions/games/?ex_cid=rrpromo)\n\n## Do teenagers get 7+ hours of sleep? {.smaller}\n\n::: columns\n::: {.column width=\"40%\"}\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\n\n`Sleep7`\n\n1: yes\n\n0: no\n:::\n\n::: {.column width=\"60%\"}\n```{r}\ndata(YouthRisk2009)\nsleep <- YouthRisk2009 %>%\n  as_tibble() %>%\n  filter(!is.na(Age), !is.na(Sleep7))\nsleep %>%\n  relocate(Age, Sleep7)\n```\n:::\n:::\n\n## Plot the data\n\n```{r}\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")\n```\n\n## Let's fit a linear regression model\n\n**Outcome:** $Y$ = 1: yes, 0: no\n\n```{r}\n#| echo: false\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(y = \"Getting 7+ hours of sleep\")\n```\n\n## Let's use proportions\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n```{r}\n#| echo: false\n\nsleep_age <- sleep %>%\n  group_by(Age) %>%\n  summarise(prop = mean(Sleep7))\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method = \"lm\",fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\")\n```\n\n## What happens if we zoom out?\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n```{r}\n#| echo: false\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method = \"lm\",fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-1, 2)\n```\n\nðŸ›‘ *This model produces predictions outside of 0 and 1.*\n\n## Let's try another model\n\n```{r}\n#| label: logistic-model-plot\n#| echo: false\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)\n```\n\n*âœ… This model (called a **logistic regression model**) only produces predictions between 0 and 1.*\n\n## The code\n\n```{r}\n#| ref.label: logistic-model-plot\n#| echo: true\n#| fig-show: hide\n```\n\n## Different types of models\n\n| Method                          | Outcome      | Model                                                     |\n|---------------------------------|--------------|-----------------------------------------------------------|\n| Linear regression               | Quantitative | $Y = \\beta_0 + \\beta_1~ X$                                |\n| Linear regression (transform Y) | Quantitative | $\\log(Y) = \\beta_0 + \\beta_1~ X$                          |\n| Logistic regression             | Binary       | $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1 ~ X$ |\n\n# Odds and probabilities\n\n## Binary response variable\n\n-   $Y = 1: \\text{ yes}, 0: \\text{ no}$\n-   $\\pi$: **probability** that $Y=1$, i.e., $P(Y = 1)$\n-   $\\frac{\\pi}{1-\\pi}$: **odds** that $Y = 1$\n-   $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$: **log odds**\n-   Go from $\\pi$ to $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$ using the **logit transformation**\n\n## Odds\n\nSuppose there is a **70% chance** it will rain tomorrow\n\n-   Probability it will rain is $\\mathbf{p = 0.7}$\n-   Probability it won't rain is $\\mathbf{1 - p = 0.3}$\n-   Odds it will rain are **7 to 3**, **7:3**, $\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}$\n\n## Are teenagers getting enough sleep?\n\n```{r}\nsleep %>%\n  count(Sleep7) %>%\n  mutate(p = round(n / sum(n), 3))\n```\n\n. . .\n\n$P(\\text{7+ hours of sleep}) = P(Y = 1) = p = 0.664$\n\n. . .\n\n$P(\\text{< 7 hours of sleep}) = P(Y = 0) = 1 - p = 0.336$\n\n. . .\n\n$P(\\text{odds of 7+ hours of sleep}) = \\frac{0.664}{0.336} = 1.976$\n\n## From odds to probabilities\n\n::: columns\n::: {.column width=\"50%\"}\n**odds**\n\n$$\\omega = \\frac{\\pi}{1-\\pi}$$\n:::\n\n::: {.column width=\"50%\"}\n**probability**\n\n$$\\pi = \\frac{\\omega}{1 + \\omega}$$\n:::\n:::\n\n## Logistic regression\n\n## From odds to probabilities\n\n(1) **Logistic model**: log odds = $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$\n(2) **Odds =** $\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}$\n(3) Combining (1) and (2) with what we saw earlier\n\n$$\\text{probability} = \\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}$$\n\n## Logistic regression model\n\n**Logit form**: $$\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$$\n\n. . .\n\n**Probability form**:\n\n$$\n\\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}\n$$\n\n## Risk of coronary heart disease\n\nThis dataset is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts.\nWe want to use `age` to predict if a randomly selected adult is high risk of having coronary heart disease in the next 10 years.\n\n`high_risk`:\n\n::: nonincremental\n-   1: High risk of having heart disease in next 10 years\n-   0: Not high risk of having heart disease in next 10 years\n:::\n\n`age`: Age at exam time (in years)\n\n## Data: `heart`\n\n```{r}\nheart_disease <- read_csv(here::here(\"slides\", \"data/framingham.csv\")) %>%\n  select(age, TenYearCHD) %>%\n  drop_na() %>%\n  mutate(high_risk = as.factor(TenYearCHD)) %>%\n  select(age, high_risk)\n\nheart_disease\n```\n\n## High risk vs. age\n\n```{r}\n#| echo: true\n\nggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot() +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. High risk of heart disease\")\n```\n\n## Let's fit the model\n\n```{r}\n#| echo: true\n\nheart_disease_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(high_risk ~ age, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) %>% kable(digits = 3)\n```\n\n## The model\n\n```{r}\n#| echo: true\n\ntidy(heart_disease_fit) %>% kable(digits = 3)\n```\n\n. . .\\\n\\\n$$\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) = -5.561 + 0.075 \\times \\text{age}$$ where $\\hat{\\pi}$ is the predicted probability of being high risk\n\n## Predicted log odds\n\n```{r}\naugment(heart_disease_fit$fit)\n```\n\n. . .\n\n**For observation 1**\n\n$$\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.650\\} = 0.071$$\n\n## Predicted probabilities\n\n```{r}\npredict(heart_disease_fit, new_data = heart_disease, type = \"prob\")\n```\n\n. . .\n\n$$\\text{predicted probabilities} = \\hat{\\pi} = \\frac{\\exp\\{-2.650\\}}{1 + \\exp\\{-2.650\\}} = 0.066$$\n\n## Predicted classes\n\n```{r}\npredict(heart_disease_fit, new_data = heart_disease, type = \"class\")\n```\n\n## Default prediction\n\nFor a logistic regression, the default prediction is the `class`.\n\n```{r}\npredict(heart_disease_fit, new_data = heart_disease)\n```\n\n## Observed vs. predicted\n\n::: question\nWhat does the following table show?\n:::\n\n```{r}\npredict(heart_disease_fit, new_data = heart_disease) %>%\n  bind_cols(heart_disease) %>%\n  count(high_risk, .pred_class)\n```\n\n## Recap\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Used logistic regression model to calculate predicted odds and probabilities\n\n## Application exercise\n\n::: appex\nðŸ“‹ [github.com/sta210-s22/ae-9-odds](https://github.com/sta210-s22/ae-9-odds)\n:::\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-18.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Logistic regression","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","transition":"fade","slideNumber":true,"chalkboard":true}}}}