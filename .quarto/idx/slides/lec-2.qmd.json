{"title":"Simple Linear Regression","markdown":{"yaml":{"title":"Simple Linear Regression","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","multiplex":true,"transition":"fade","slide-number":true}},"editor":"visual","execute":{"freeze":"auto"}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r setup}\nlibrary(countdown)\nknitr::opts_chunk$set(\n  fig.width = 6,\n  fig.asp = 0.618,\n  fig.align = \"center\",\n  out.width = \"90%\"\n)\n```\n\n# Welcome\n\n## Announcements\n\n-   If you're just joining the class, welcome! Go to the [course website](https://sta210-s22.github.io/website) and review content you've missed, read the syllabus, and complete the *Getting to know you* survey.\n-   Lab 1 is due Friday, at 5pm, on Gradescope.\n\n## Dorianne Gray says...\n\n[![](images/lec-2/dorianne-gray.jpeg){fig-alt=\"Picture of my cat Dorianne Gray (a gray, furry tabby) with a speech bubble that says \\\"Read the syllabus and make Mine happy!\\\"\" width=\"800\"}](https://sta210-s22.github.io/website/course-syllabus.html)\n\n## Outline\n\n-   Use simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable\n-   Estimate the slope and intercept of the regression line using the least squares method\n-   Interpret the slope and intercept of the regression line\n\n## Computational setup\n\n```{r packages}\n#| echo: true\n#| message: false\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)\n```\n\n# Data\n\n## Movie ratings\n\n::: columns\n::: {.column width=\"70%\"}\n-   Data behind the FiveThirtyEight story [*Be Suspicious Of Online Movie Ratings, Especially Fandango's*](%22Be%20Suspicious%20Of%20Online%20Movie%20Ratings,%20Especially%20Fandango's%22)\n-   In the **fivethirtyeight** package: [`fandango`](https://fivethirtyeight-r.netlify.app/reference/fandango.html)\n-   Contains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores\n:::\n\n::: {.column width=\"30%\"}\n![](images/lec-2/fandango.png){fig-alt=\"Fandango logo\" width=\"200\"}\n\n![](images/lec-2/imdb.png){fig-alt=\"IMDB logo\" width=\"200\"}\n\n![](images/lec-2/rotten-tomatoes.png){fig-alt=\"Rotten Tomatoes logo\" width=\"200\"}\n\n![](images/lec-2/metacritic.png){fig-alt=\"Metacritic logo\" width=\"200\"}\n:::\n:::\n\n## Data prep\n\n-   Rename Rotten Tomatoes columns as `critics` and `audience`\n-   Rename the dataset as `movie_scores`\n\n```{r data-prep}\n#| echo: true\nmovie_scores <- fandango %>%\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )\n```\n\n## Data overview\n\n```{r data-overview}\n#| echo: true\nglimpse(movie_scores)\n```\n\n## Data visualization\n\n```{r}\nggplot(movie_scores, \n       aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) + \n  labs(\n    x = \"Critics Score\" , \n    y = \"Audience Score\"\n    )\n```\n\n# Regression model\n\n## Fit a line\n\n... to *describe* the relationship between the critics and audience score\n\n```{r}\n#| out.width: \"70%\"\np <- ggplot(data = movie_scores, \n       mapping = aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  labs(\n    x = \"Critics Score\" , \n    y = \"Audience Score\"\n    )\n\np\n```\n\n## Terminology\n\n::: columns\n::: {.column width=\"30%\"}\n-   **Outcome, *Y***: variable describing the outcome of interest\n-   **Predictor, X**: variable used to help understand the variability in the outcome\n:::\n\n::: {.column width=\"70%\"}\n```{r}\n#| out.width: \"100%\"\np\n```\n:::\n:::\n\n## Regression model {#regression-model-1}\n\nA **regression model** is a function that describes the relationship between the outcome, $Y$, and the predictor, $X$.\n\n$$\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}$$\n\n## Regression model\n\n::: columns\n::: {.column width=\"30%\"}\n$$\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \n\\end{aligned}\n$$\n:::\n\n::: {.column width=\"70%\"}\n```{r}\nm <- lm(audience ~ critics, data = movie_scores)\n\nggplot(data = movie_scores, \n       mapping = aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  labs(x = \"X\", y = \"Y\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks.x = element_blank(), \n    axis.ticks.y = element_blank()\n    )\n```\n:::\n:::\n\n## Regression model + residuals\n\n::: columns\n::: {.column width=\"30%\"}\n$$\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n \\end{aligned}$$\n:::\n\n::: {.column width=\"70%\"}\n```{r}\n#| echo: false\nggplot(data = movie_scores,\n       mapping = aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  geom_segment(aes(x = critics, xend = critics, \n                   y = audience, yend = predict(m)), \n               color = \"blue\") +\n  labs(x = \"X\", y = \"Y\") +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n```\n:::\n:::\n\n# Simple linear regression\n\n## Simple linear regression\n\nUse **simple linear regression** to model the relationthip between a quantitative outcome ($Y$) and a single quantitative predictor ($X$): $$\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}$$\n\n::: incremental\n-   $\\beta_1$: True slope of the relationship between $X$ and $Y$\n-   $\\beta_0$: True intercept of the relationship between $X$ and $Y$\n-   $\\epsilon$: Error (residual)\n:::\n\n## Simple linear regression\n\n$$\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}$$\n\n-   $\\hat{\\beta}_1$: Estimated slope of the relationship between $X$ and $Y$\n-   $\\hat{\\beta}_0$: Estimated intercept of the relationship between $X$ and $Y$\n-   No error term!\n\n## Choosing values for $\\hat{\\beta}_1$ and $\\hat{\\beta}_0$\n\n```{r}\nggplot(data = movie_scores, \n       mapping = aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.4) + \n  geom_abline(intercept = 32.3155, slope = 0.5187, color = \"purple\", size = 1) +\n  geom_abline(intercept = 25, slope = 0.7, color = \"gray\") +\n  geom_abline(intercept = 21, slope = 0.9, color = \"gray\") +\n  geom_abline(intercept = 35, slope = 0.3, color = \"gray\") +\n  labs(x = \"Critics Score\", y = \"Audience Score\")\n```\n\n## Residuals\n\n```{r}\n#| warning: false\n#| message: false\nggplot(data = movie_scores, mapping = aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"purple\", se = FALSE) +\n  geom_segment(aes(x = critics, xend = critics, y = audience, yend = predict(m)), color = \"steel blue\") +\n  labs(x = \"Critics Score\", y = \"Audience Score\") +\n  theme(legend.position = \"none\")\n```\n\n$$\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}$$\n\n## Least squares line\n\n-   The residual for the $i^{th}$ observation is\n\n$$e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i$$\n\n-   The **sum of squared** residuals is\n\n$$e^2_1 + e^2_2 + \\dots + e^2_n$$\n\n-   The **least squares line** is the one that minimizes the sum of squared residuals\n\n```{r}\nsx <- round(sqrt(var(movie_scores$critics)), 4)\nsy <- round(sqrt(var(movie_scores$audience)), 4)\nr <- round(cor(movie_scores$critics, movie_scores$audience), 4)\nxbar <- round(mean(movie_scores$critics), 4)\nybar <- round(mean(movie_scores$audience), 4)\n```\n\n# Slope and intercept\n\n## Properties of least squares regression\n\n-   The regression line goes through the center of mass point, the coordinates corresponding to average $X$ and average $Y$: $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}$\n\n-   The slope has the same sign as the correlation coefficient: $\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}$\n\n-   The sum of the residuals is zero: $\\sum_{i = 1}^n \\epsilon_i = 0$\n\n-   The residuals and $X$ values are uncorrelated\n\n## Estimating the slope\n\n$$\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}$$\n\n::: columns\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned} \ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\n$$\n:::\n\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\n$$\n:::\n:::\n\n## Estimating the intercept\n\n$$\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}$$\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}$$\n:::\n\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\n$$\n:::\n:::\n\n## Interpreting the slope {.smaller}\n\n**Poll:** The slope of the model for predicting audience score from critics score is 32.3142.\nWhich of the following is the best interpretation of this value?\n\n-   For every one point increase in the critics score, the audience score goes up by 0.5187 points, on average.\n-   For every one point increase in the critics score, we expect the audience score to be higher by 0.5187 points, on average.\n-   For every one point increase in the critics score, the audience score goes up by 0.5187 points.\n-   For every one point increase in the audience score, the critics score goes up by 0.5187 points, on average.\n\n## Interpreting slope & intercept\n\n$$\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}$$\n\n::: incremental\n-   **Slope:** For every one point increase in the critics score, we expect the audience score to be higher by 0.5187 points, on average.\n-   **Intercept:** If the critics score is 0 points, we expect the audience score to be 32.3142 points.\n:::\n\n## Is the intercept meaningful?\n\nâœ… The intercept is meaningful in context of the data if\n\n-   the predictor can feasibly take values equal to or near zero or\n-   the predictor has values near zero in the observed data\n\n. . .\n\nðŸ›‘ Otherwise, it might not be meaningful!\n\n# Prediction\n\n## Making a prediction\n\nSuppose that a movie has a critics score of 50.\nAccording to this model, what is the movie's predicted audience score?\n\n$$\n\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 50 \\\\\n&= 58.2492\n\\end{aligned}\n$$\n\n## Extrapolation\n\nSuppose that a movie has a critics score of 0.\nAccording to this model, what is the movie's predicted audience score?\n\n```{r}\np + coord_cartesian(xlim = c(0, 100))\n```\n\n# Recap\n\n## Recap {.smaller}\n\n::: incremental\n-   Used simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.\n\n-   Used the least squares method to estimate the slope and intercept.Ã¥\n\n-   We interpreted the slope and intercept.\n\n    ::: incremental\n    -   **Slope:** For every one unit increase in $x$, we expect y to be higher/lower by $\\hat{\\beta}_1$ units, on average.\n    -   **Intercept:** If $x$ is 0, then we expect $y$ to be $\\hat{\\beta}_0$ units.\n    :::\n\n-   Predicted the response given a value of the predictor variable.\n\n-   Defined extrapolation and why we should avoid it.\n:::\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"lec-2.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Simple Linear Regression","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","multiplex":true,"transition":"fade","slideNumber":true}}}}