{"title":"Cross validation","markdown":{"yaml":{"title":"Cross validation","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","multiplex":true,"transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto","echo":true}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 10, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n```\n\n# Welcome\n\n## Topics\n\n::: nonincremental\n-   Cross validation for model evaluation\n-   Cross validation for model comparison\n:::\n\n## Computational setup\n\n```{r}\n#| echo: true\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(schrute)\n```\n\n## Data & goal {.smaller}\n\n::: nonincremental\n-   Data: The data come from the [**shrute**](https://bradlindblad.github.io/schrute/) package, and has been transformed using instructions from [Lab 4](/labs/lab-4.html)\n-   Goal: Predict `imdb_rating` from other variables in the dataset\n:::\n\n```{r}\n#| echo: true\n\noffice_episodes <- read_csv(here::here(\"slides\", \"data/office_episodes.csv\"))\noffice_episodes\n```\n\n# Modeling prep\n\n## Split data into training and testing\n\n```{r}\nset.seed(123)\noffice_split <- initial_split(office_episodes)\noffice_train <- training(office_split)\noffice_test <- testing(office_split)\n```\n\n## Specify model\n\n```{r}\noffice_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_spec\n```\n\n# Model 1\n\n## From yesterday's lab\n\n-   Create a recipe that uses the new variables we generated\n-   Denotes `episode_name` as an ID variable and doesn't use `air_date` as a predictor\n-   Create dummy variables for all nominal predictors\n-   Remove all zero variance predictors\n\n## Create recipe\n\n```{r}\noffice_rec1 <- recipe(imdb_rating ~ ., data = office_train) %>%\n  update_role(episode_name, new_role = \"id\") %>%\n  step_rm(air_date) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors())\n\noffice_rec1\n```\n\n## Create workflow\n\n```{r}\noffice_wflow1 <- workflow() %>%\n  add_model(office_spec) %>%\n  add_recipe(office_rec1)\n\noffice_wflow1\n```\n\n## Fit model to training data\n\n. . .\n\n*Actually, not so fast!*\n\n# Cross validation\n\n## Spending our data\n\n-   We have already established that the idea of data spending where the test set was recommended for obtaining an unbiased estimate of performance.\n-   However, we usually need to understand the effectiveness of the model *before using the test set*.\n-   Typically we can't decide on *which* final model to take to the test set without making model assessments.\n-   Remedy: Resampling to make model assessments on training data in a way that can generalize to new data.\n\n## Resampling for model assessment\n\n**Resampling is only conducted on the training set**.\nThe test set is not involved.\nFor each iteration of resampling, the data are partitioned into two subsamples:\n\n-   The model is fit with the **analysis set**.\n-   The model is evaluated with the **assessment set**.\n\n## Resampling for model assessment\n\n![](images/lec-14/resampling.svg){fig-align=\"center\"}\n\n<br>\n\nSource: Kuhn and Silge.\n[Tidy modeling with R](https://www.tmwr.org/).\n\n## Analysis and assessment sets\n\n-   Analysis set is analogous to training set.\n-   Assessment set is analogous to test set.\n-   The terms *analysis* and *assessment* avoids confusion with initial split of the data.\n-   These data sets are mutually exclusive.\n\n## Cross validation\n\nMore specifically, **v-fold cross validation** -- commonly used resampling technique:\n\n-   Randomly split your **training** **data** into v partitions\n-   Use 1 partition for assessment, and the remaining v-1 partitions for analysis\n-   Repeat v times, updating which partition is used for assessment each time\n\n. . .\n\nLet's give an example where `v = 3`...\n\n## Cross validation, step 1\n\nRandomly split your **training** **data** into 3 partitions:\n\n<br>\n\n![](images/lec-14/three-CV.svg){fig-align=\"center\"}\n\n## Split data\n\n```{r}\n#| echo: true\n\nset.seed(345)\nfolds <- vfold_cv(office_train, v = 3)\nfolds\n```\n\n## Cross validation, steps 2 and 3\n\n::: nonincremental\n-   Use 1 partition for assessment, and the remaining v-1 partitions for analysis\n-   Repeat v times, updating which partition is used for assessment each time\n:::\n\n![](images/lec-14/three-CV-iter.svg){fig-align=\"center\"}\n\n## Fit resamples\n\n```{r}\n#| echo: true\n\nset.seed(456)\n\noffice_fit_rs1 <- office_wflow1 %>%\n  fit_resamples(folds)\n\noffice_fit_rs1\n```\n\n## Cross validation, now what?\n\n-   We've fit a bunch of models\n-   Now it's time to use them to collect metrics (e.g., R-squared, RMSE) on each model and use them to evaluate model fit and how it varies across folds\n\n## Collect CV metrics\n\n```{r}\ncollect_metrics(office_fit_rs1)\n```\n\n## Deeper look into CV metrics\n\n```{r}\ncv_metrics1 <- collect_metrics(office_fit_rs1, summarize = FALSE) \n\ncv_metrics1\n```\n\n## Better tabulation of CV metrics\n\n```{r}\ncv_metrics1 %>%\n  mutate(.estimate = round(.estimate, 3)) %>%\n  pivot_wider(id_cols = id, names_from = .metric, values_from = .estimate) %>%\n  kable(col.names = c(\"Fold\", \"RMSE\", \"R-squared\"))\n```\n\n## How does RMSE compare to y? {.smaller}\n\nCross validation RMSE stats:\n\n```{r}\ncv_metrics1 %>%\n  filter(.metric == \"rmse\") %>%\n  summarise(\n    min = min(.estimate),\n    max = max(.estimate),\n    mean = mean(.estimate),\n    sd = sd(.estimate)\n  )\n```\n\nTraining data IMDB score stats:\n\n```{r}\noffice_episodes %>%\n  summarise(\n    min = min(imdb_rating),\n    max = max(imdb_rating),\n    mean = mean(imdb_rating),\n    sd = sd(imdb_rating)\n  )\n```\n\n## Cross validation jargon\n\n-   Referred to as v-fold or k-fold cross validation\n-   Also commonly abbreviated as CV\n\n## Cross validation, for reals\n\n-   To illustrate how CV works, we used `v = 3`:\n\n    ::: nonincremental\n    -   Analysis sets are 2/3 of the training set\n    -   Each assessment set is a distinct 1/3\n    -   The final resampling estimate of performance averages each of the 3 replicates\n    :::\n\n-   This was useful for illustrative purposes, but `v = 3` is a poor choice in practice\n\n-   Values of `v` are most often 5 or 10; we generally prefer 10-fold cross-validation as a default\n\n# Application exercise\n\n::: appex\nðŸ“‹ [github.com/sta210-s22/ae-6-the-office-cv](https://github.com/sta210-s22/ae-6-the-office-cv)\n:::\n\n## Recap\n\n::: nonincremental\n-   Cross validation for model evaluation\n-   Cross validation for model comparison\n:::\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-14.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Cross validation","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","multiplex":true,"transition":"fade","slideNumber":true,"chalkboard":true}}}}