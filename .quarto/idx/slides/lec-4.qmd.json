{"title":"SLR: Prediction + model evaluation","markdown":{"yaml":{"title":"SLR: Prediction + model evaluation","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","multiplex":true,"transition":"fade","slide-number":true,"incremental":true}},"editor":"visual","execute":{"freeze":"auto"}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r setup}\n\nlibrary(countdown)\n\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)\n```\n\n# Welcome\n\n## Announcements\n\n-   New on the course website: [FAQ](/course-faq.html)\n-   New communication tool: Slack\n    -   Find the invite link in your inbox / on Sakai announcements\n    -   Use #general for questions, #random for random 🤪\n    -   Use code formatting for for questions involving code (see Course FAQ for a demo video)\n-   My office hours: All virtual for now, hope to move 1 hour / week to in person later in the semester\n\n## Hybrid teaching {.smaller}\n\n-   Lectures:\n    -   In person as long as university says so (and I don't have COVID)\n    -   If you can't be in class (and you're well enough to follow along), watch live (or the recording later) on [Panopto](https://duke.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22d6c1d58a-cb6d-4732-9d4b-ae0c011bf767%22)\n    -   Watching live and have questions? Post on Slack!\n    -   In class and see someone ask a question on Slack? Please raise it to me!\n-   Labs:\n    -   Not live streamed / recorded\n    -   Lab 2 (next Monday) - individual\n    -   Lab 3 onwards - in teams, if teammates are in isolation, set up team Zoom calls\n\n## Computational setup\n\n```{r packages}\n#| echo: true\n#| message: false\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n```\n\n# Application exercise\n\n::: appex\n📋 [github.com/sta210-s22/ae-2-dcbikeshare](https://github.com/sta210-s22/?q=ae-2-dcbikeshare&type=all&language=&sort=)\n:::\n\n# Uninsurance and high school graduation rates in NC\n\n## Data source\n\n-   The data come from [`usdata::county_2019`](https://openintrostat.github.io/usdata/reference/county_2019.html)\n-   These data have been compiled from the 2019 American Community Survey\n\n```{r map-prep}\n# data prop for mapping\ndfips <- maps::county.fips %>%\n  as_tibble() %>% \n  extract(polyname, c(\"region\", \"subregion\"), \"^([^,]+),([^,]+)$\") %>%\n  filter(region %in% c(\"north carolina\", \"new york\"))\n\nmap_county_2019 <- map_data(\"county\") %>%\n  as_tibble() %>%\n  filter(region %in% c(\"north carolina\", \"new york\")) %>%\n  left_join(dfips) %>%\n  mutate(fips = if_else(\n    subregion == \"currituck\" & region == \"north carolina\", 37053L, fips\n  )) %>%\n  left_join(county_2019, by = \"fips\")\n\nmap_county_2019_nc <- map_county_2019 %>%\n  filter(state == \"North Carolina\")\n```\n\n## Uninsurance rate\n\n```{r}\n#| out.width: \"100%\"\nggplot(map_county_2019_nc, \n       aes(x = long, y = lat, group = group)) +\n  geom_polygon(aes(fill = uninsured)) +\n  scale_fill_viridis_c(option = \"E\", labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = NULL, y = NULL, fill = NULL,\n    title = \"Percent uninsured (2015 - 2019)\",\n    subtitle = \"Civilian noninstitutionalized population in NC\"\n  ) +\n  coord_quickmap(clip = \"off\") +\n  theme_void() +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position = c(0.2, 0.1),\n  ) +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"durham\"), aes(fill = uninsured), color = \"white\") +\n  annotate(\"text\", x = -78.7, y = 36.3, label = \"Durham County\\n(12%)\", hjust = 0, size = 4, color = \"white\", fontface = \"bold\") +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"swain\"), aes(fill = uninsured), color = \"black\") +\n  annotate(\"text\", x = -83.4, y = 35.9, label = \"Swain County\\n(21.5%)\", hjust = 1, size = 4, fontface = \"bold\") +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"gates\"), aes(fill = uninsured), color = \"black\") +\n  annotate(\"text\", x = -76.9, y = 36.8, label = \"Gates County\\n(6.6%)\", hjust = 0, size = 4, color = \"black\", fontface = \"bold\")\n```\n\n## High school graduation rate\n\n```{r}\n#| out.width: \"100%\"\nmap_county_2019 %>%\n  filter(state == \"North Carolina\") %>%\n  ggplot(aes(x = long, y = lat, group = group)) +\n  geom_polygon(aes(fill = hs_grad)) +\n  scale_fill_viridis_c(option = \"D\", labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(x = NULL, y = NULL, fill = NULL,\n    title = \"Percent high school graduate (2015 - 2019)\",\n    subtitle = \"25 and older population in NC\") +\n  coord_quickmap(clip = \"off\") +\n  theme_void() +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position = c(0.2, 0.1),\n  ) +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"durham\"), aes(fill = hs_grad), color = \"white\") +\n  annotate(\"text\", x = -78.7, y = 36.3, label = \"Durham County\\n(88.4%)\", hjust = 0, size = 4, color = \"white\", fontface = \"bold\") +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"tyrrell\"), aes(fill = hs_grad), color = \"black\") +\n  annotate(\"text\", x = -76.4, y = 36.3, label = \"Tyrrell\\nCounty\\n(74%)\", hjust = 0, size = 4, color = \"black\", fontface = \"bold\") +\n  geom_polygon(data = map_county_2019_nc %>% filter(subregion == \"dare\"), aes(fill = hs_grad), color = \"black\") +\n  annotate(\"text\", x = -75.9, y = 35.2, label = \"Dare\\nCounty\\n(94.2%)\", hjust = 0, size = 4, color = \"black\", fontface = \"bold\")\n```\n\n## Examining the relationship\n\n-   The [NC Labor and Economic Analysis Division (LEAD)](https://www.nc.gov/agency/labor-and-economic-analysis-division), which \"administers and collects data, conducts research, and publishes information on the state's economy, labor force, educational, and workforce-related issues\".\n-   Suppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n\n. . .\n\n::: question\nWhat type of visualization should the analyst make to examine the relationship between these two variables?\n:::\n\n## Data prep\n\n```{r}\n#| echo: true\n\ncounty_2019_nc <- county_2019 %>%\n  as_tibble() %>%\n  filter(state == \"North Carolina\") %>%\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n```\n\n## Uninsurance vs. HS graduation rates\n\n```{r nc-uninsured-hsgrad-scatter}\n#| code-fold: true\n#| echo: true\n\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc %>% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc %>% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)\n```\n\n## Modeling the relationship\n\n```{r nc-uninsured-hsgrad-scatter-line}\n#| code-fold: true\n#| echo: true\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )\n```\n\n## Fitting the model\n\nWith `fit()`:\n\n```{r}\n#| echo: true\n\nnc_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n```\n\n## Augmenting the data\n\nWith `augment()` to add columns for predicted values (`.fitted`), residuals (`.resid`), etc.:\n\n```{r}\n#| echo: true\n\nnc_aug <- augment(nc_fit$fit)\nnc_aug\n```\n\n## Visualizing the model I {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   **Black circles:** Observed values (`y = uninsured`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out-width: \"100%\"\n\np_nc_aug_base <- ggplot(nc_aug, aes(x = hs_grad)) +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(x = \"High school graduate\", y = \"Uninsured\")\n\np_nc_aug_base +\n  geom_point(aes(y = uninsured))\n```\n:::\n:::\n\n## Visualizing the model II {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   **Pink solid line:** Least squares regression line\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out-width: \"100%\"\n\np_nc_aug_base +\n  geom_point(aes(y = uninsured)) +\n  geom_smooth(aes(y = uninsured), method = \"lm\", se = FALSE, color = \"pink\")\n```\n:::\n:::\n\n## Visualizing the model III {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   **Maroon triangles:** Predicted values (`y = .fitted`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out-width: \"100%\"\n\np_nc_aug_base +\n  geom_point(aes(y = uninsured)) +\n  geom_smooth(aes(y = uninsured), method = \"lm\", se = FALSE, color = \"pink\") +\n  geom_point(aes(y = .fitted), color = \"maroon\", shape = \"triangle\", size = 2)\n```\n:::\n:::\n\n## Visualizing the model IV {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   Maroon triangles: Predicted values (`y = .fitted`)\n-   **Gray dashed lines:** Residuals\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out-width: \"100%\"\n\np_nc_aug_base +\n  geom_segment(aes(xend = hs_grad, y = uninsured, yend = .fitted), size = 0.3, linetype = \"dashed\", color = \"gray20\") +\n  geom_point(aes(y = uninsured)) +\n  geom_smooth(aes(y = uninsured), method = \"lm\", se = FALSE, color = \"pink\") +\n  geom_point(aes(y = .fitted), color = \"maroon\", shape = \"triangle\", size = 2)\n```\n:::\n:::\n\n## Evaluating the model fit\n\n::: question\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?\n:::\n\n# Model evaluation\n\n## Two statistics {.smaller}\n\n-   **R-squared**, $R^2$ : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n    $$\n    R^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n    $$\n\n-   **Root mean square error, RMSE**: A measure of the average error (average difference between observed and predicted values of the outcome)\n\n    $$\n    RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n    $$\n\n. . .\n\n::: question\nWhat indicates a good model fit?\nHigher or lower $R^2$?\nHigher or lower RMSE?\n:::\n\n## R-squared {.smaller}\n\n-   Ranges between 0 (terrible predictor) and 1 (perfect predictor)\n\n-   Unitless\n\n-   Calculate with `rsq()`:\n\n    ```{r}\n    #| echo: true\n    rsq(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n\n## Interpreting R-squared {.smaller}\n\n```{r}\nnc_fit_rsq <- round(glance(nc_fit)$r.squared * 100, 1)\n```\n\n::: poll\n🗳️ **Vote on Slack**\n\nThe $R^2$ of the model for predicting uninsurance rate from high school graduation rate for NC counties is `r nc_fit_rsq`%.\nWhich of the following is the correct interpretation of this value?\n\n::: nonincremental\n-   High school graduation rates correctly predict `r nc_fit_rsq`% of uninsurance rates in NC counties.\n-   `r nc_fit_rsq`% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n-   `r nc_fit_rsq`% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n-   `r nc_fit_rsq`% of the time uninsurance rates in NC counties can be predicted by high school graduation rates.\n:::\n:::\n\n## Alternative approach for R-squared\n\nAlternatively, use `glance()` to construct a single row summary of the model fit, including $R^2$:\n\n```{r}\n#| echo: true\n\nglance(nc_fit)\nglance(nc_fit)$r.squared\n```\n\n## RMSE\n\n-   Ranges between 0 (perfect predictor) and infinity (terrible predictor)\n\n-   Same units as the outcome variable\n\n-   Calculate with `rmse()`:\n\n    ```{r}\n    #| echo: true\n\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n\n-   The value of RMSE is not very meaningful on its own, but it's useful for comparing across models (more on this when we get to regression with multiple predictors)\n\n## Obtaining R-squared and RMSE {.smaller}\n\n-   Use `rsq()` and `rmse()`, respectively\n\n    ```{r}\n    #| echo: true\n    #| eval: false\n\n    rsq(nc_aug, truth = uninsured, estimate = .fitted)\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n\n-   First argument: data frame containing `truth` and `estimate` columns\n\n-   Second argument: name of the column containing `truth` (observed outcome)\n\n-   Third argument: name of the column containing `estimate` (predicted outcome)\n\n## Purpose of model evaluation\n\n-   $R^2$ tells us how our model is doing to predict the data we *already have*\n-   But generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e. **out-of-sample prediction**\n-   We have a couple ways of *simulating* out-of-sample prediction before actually getting new data to evaluate the performance of our models\n\n# Splitting data\n\n## Spending our data\n\n-   There are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\n-   Doing all of this on the entire data we have available leaves us with no other data to assess our choices\n-   We can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we've done so far)\n\n## Simulation: data splitting {.smaller}\n\n::: columns\n::: {.column width=\"30%\"}\n::: nonincremental\n-   Take a random sample of 10% of the data and set aside (testing data)\n-   Fit a model on the remaining 90% of the data (training data)\n-   Use the coefficients from this model to make predictions for the testing data\n-   Repeat 10 times\n:::\n:::\n\n::: {.column width=\"70%\"}\n```{r}\n#| out.width: \"100%\"\n\nset.seed(345)\n\nn_folds <- 10\n\ncounty_2019_nc_folds <- county_2019_nc %>%\n  slice_sample(n = nrow(county_2019_nc)) %>%\n  mutate(fold = rep(1:n_folds, n_folds)) %>%\n  arrange(fold)\n\npredict_folds <- function(i) {\n  fit <- lm(uninsured ~ hs_grad, data = county_2019_nc_folds %>% filter(fold != i))\n  predict(fit, newdata = county_2019_nc_folds %>% filter(fold == i)) %>%\n    bind_cols(county_2019_nc_folds %>% filter(fold == i), .fitted = .)\n}\n\nnc_fits <- map_df(1:n_folds, predict_folds)\n\np_nc_fits <- ggplot(nc_fits, aes(x = hs_grad, y = .fitted, group = fold)) +\n  geom_line(stat = \"smooth\", method = \"lm\", se = FALSE, size = 0.3, alpha = 0.5) +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Predicted uninsurance rate in NC\",\n    subtitle = glue(\"For {n_folds} different testing datasets\")\n    )\n\np_nc_fits\n```\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different testing datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out.width: \"100%\"\n\np_nc_fits\n```\n:::\n:::\n\n# Bootstrapping\n\n## Bootstrapping our data {.smaller}\n\n-   The idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\n-   With bootstrapping, we simulate resampling from the population by resampling from the sample we observed\n-   Bootstrap samples are the sampled *with replacement* from the original sample and same size as the original sample\n    -   For example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc.\n\n## Simulation: bootstrapping {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Take a bootstrap sample -- sample with replacement from the original data, same size as the original data\n-   Fit model to the sample and make predictions for that sample\n-   Repeat many times\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out.width: \"100%\"\n\nn_boot <- 100\n\npredict_boots <- function(i){\n  boot <- county_2019_nc %>%\n    slice_sample(n = nrow(county_2019_nc), replace = TRUE) %>%\n    mutate(boot_samp = i)\n  fit <- lm(uninsured ~ hs_grad, data = boot)\n  predict(fit) %>% bind_cols(boot, .fitted = .)\n}\n\nset.seed(1234)\ncounty_2019_nc_boots <- map_df(1:n_boot, predict_boots)\n\np_nc_boots <- ggplot(county_2019_nc_boots, aes(x = hs_grad, y = .fitted, group = boot_samp)) +\n  geom_line(stat = \"smooth\", method = \"lm\", se = FALSE, size = 0.3, alpha = 0.5) +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Predicted uninsurance rate in NC\",\n    subtitle = glue(\"For {n_boot} bootstrap samples\")\n    )\n\np_nc_boots\n```\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different bootstrap datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n```{r}\n#| out.width: \"100%\"\n\np_nc_boots\n```\n:::\n:::\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-4.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"SLR: Prediction + model evaluation","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","multiplex":true,"transition":"fade","slideNumber":true}}}}