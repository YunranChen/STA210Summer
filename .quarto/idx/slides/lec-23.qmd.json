{"title":"Multinomial Logistic Regression (MultiLR)","markdown":{"yaml":{"title":"Multinomial Logistic Regression (MultiLR)","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto","echo":true}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 8, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n\nlibrary(countdown)\n```\n\n# Welcome\n\n## Topics\n\n::: nonincremental\n-   Introduce multinomial logistic regression\n\n-   Interpret model coefficients\n\n-   Inference for a coefficient $\\beta_{jk}$\n:::\n\n## Computational setup\n\n```{r}\n#| echo: true\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(NHANES)\nlibrary(knitr)\nlibrary(patchwork)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n# Generalized Linear Models\n\n## Generalized Linear Models (GLMs) {.smaller}\n\n-   In practice, there are many different types of outcome variables:\n\n    ::: nonincremental\n    -   **Binary**: Win or Lose\n    -   **Nominal**: Democrat, Republican or Third Party candidate\n    -   **Ordered**: Movie rating (1 - 5 stars)\n    -   and others...\n    :::\n\n-   Predicting each of these outcomes requires a **generalized linear model**, a broader class of models that *generalize* the multiple linear regression model\n\n::: callout-note\nRecommended reading for more details about GLMs: [*Generalized Linear Models: A Unifying Theory*](https://bookdown.org/roback/bookdown-bysh/ch-glms.html).\n:::\n\n## Binary outcome (Logistic)\n\n-   Given $P(y_i=1|x_i)= \\hat{\\pi}_i\\hspace{5mm} \\text{ and } \\hspace{5mm}P(y_i=0|x_i) = 1-\\hat{\\pi}_i$\n\n    $$\n    \\log\\Big(\\frac{\\hat{\\pi}_i}{1-\\hat{\\pi}_i}\\Big) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}\n    $$\n\n-   We can calculate $\\hat{\\pi}_i$ by solving the logit equation:\n\n    $$\n    \\hat{\\pi}_i = \\frac{e^{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}}}{1 + e^{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}}}\n    $$\n\n## Binary outcome (Logistic) {.smaller}\n\n-   Suppose we consider $y=0$ the **baseline category** such that\n\n    $$\n    P(y_i=1|x_i) = \\hat{\\pi}_{i1} \\hspace{2mm}  \\text{ and } \\hspace{2mm} P(y_i=0|x_i) = \\hat{\\pi}_{i0}\n    $$\n\n-   Then the logistic regression model is\n\n    $$\n    \\log\\bigg(\\frac{\\hat{\\pi}_{i1}}{1- \\hat{\\pi}_{i1}}\\bigg) = \\log\\bigg(\\frac{\\hat{\\pi}_{i1}}{\\hat{\\pi}_{i0}}\\bigg) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n    $$\n\n-   Slope, $\\hat{\\beta}_1$: When $x$ increases by one unit, the odds of $y=1$ versus the baseline $y=0$ are expected to multiply by a factor of $e^{\\hat{\\beta}_1}$\n\n-   Intercept, $\\hat{\\beta}_0$: When $x=0$, the predicted odds of $y=1$ versus the baseline $y=0$ are $\\exp\\{\\hat{\\beta}_0\\}$\n\n## Multinomial outcome variable\n\n-   Suppose the outcome variable $y$ is categorical and can take values $1, 2, \\ldots, K$ such that $(K > 2)$\n\n-   **Multinomial Distribution:**\n\n    $$\n    P(y=1) = \\pi_1, P(y=2) = \\pi_2, \\ldots, P(y=K) = \\pi_K\n    $$\n\n    such that $\\sum\\limits_{k=1}^{K} \\pi_k = 1$\n\n## Multinomial Logistic Regression {.smaller}\n\n-   If we have an explanatory variable $x$, then we want to fit a model such that $P(y = k) = \\pi_k$ is a function of $x$\n\n-   Choose a baseline category.\n    Let's choose $y=1$.\n    Then,\n\n    $$\n    \\log\\bigg(\\frac{\\pi_{ik}}{\\pi_{i1}}\\bigg) = \\beta_{0k} + \\beta_{1k} x_i\n    $$\n\n-   In the multinomial logistic model, we have a separate equation for each category of the outcome relative to the baseline category\n\n    -   If the outcome has $K$ possible categories, there will be $K-1$ equations as part of the multinomial logistic model\n\n## Multinomial Logistic Regression\n\n-   Suppose we have a outcome variable $y$ that can take three possible outcomes that are coded as \"A\", \"B\", \"C\"\n\n-   Let \"A\" be the baseline category.\n    Then\n\n    $$\n    \\log\\bigg(\\frac{\\pi_{iB}}{\\pi_{iA}}\\bigg) = \\beta_{0B} + \\beta_{1B}x_i \\\\[10pt]\n    \\log\\bigg(\\frac{\\pi_{iC}}{\\pi_{iA}}\\bigg) = \\beta_{0C} + \\beta_{1C} x_i\n    $$\n\n# Data\n\n## NHANES Data\n\n-   [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS)\n\n-   The goal is to *\"assess the health and nutritional status of adults and children in the United States\"*\n\n-   This survey includes an interview and a physical examination\n\n## NHANES Data\n\n-   We will use the data from the `NHANES` R package\n\n-   Contains 75 variables for the 2009 - 2010 and 2011 - 2012 sample years\n\n-   The data in this package is modified for educational purposes and should **not** be used for research\n\n-   Original data can be obtained from the [NCHS website](https://www.cdc.gov/nchs/data_access/index.htm) for research purposes\n\n-   Type `?NHANES` in console to see list of variables and definitions\n\n## Variables\n\n**Goal:** Use a person's age and whether they do regular physical activity to predict their self-reported health rating.\n\n-   Outcome: `HealthGen`: Self-reported rating of participant's health in general.\n    Excellent, Vgood, Good, Fair, or Poor.\n\n-   Predictors:\n\n    -   `Age`:Age at time of screening (in years). Participants 80 or older were recorded as 80.\n    -   `PhysActive`: Participant does moderate to vigorous-intensity sports, fitness or recreational activities.\n\n## The data\n\n```{r}\nnhanes_adult <- NHANES %>%\n  filter(Age >= 18) %>%\n  select(HealthGen, Age, PhysActive) %>%\n  drop_na() %>%\n  mutate(obs_num = 1:n())\n```\n\n. . .\n\n```{r}\nglimpse(nhanes_adult)\n```\n\n## Exploratory data analysis\n\n```{r}\n#| echo: false\n#| out-width: \"80%\"\n#| fig-width: 12\n\np1 <- ggplot(data = nhanes_adult, aes(x = Age)) + \n  geom_histogram(binwidth = 2) +\n  labs(title = \"Distribution of Age\")\n\np2 <- ggplot(data = nhanes_adult, aes(x = PhysActive)) + \n  geom_bar() +\n  labs(title = \"Moderate or vigorous\\nsport or exercise\")\n\np3 <- ggplot(data = nhanes_adult, aes(y = HealthGen)) + \n  geom_bar() +\n  labs(title = \"Self-reported rating\\nof overall health\")\n\np3 + (p1 / p2)\n```\n\n## Exploratory data analysis\n\n```{r}\n#| echo: false\n#| out-width: \"80%\"\n#| fig-width: 12\n\np1 <- ggplot(data = nhanes_adult, aes(x = HealthGen, y = Age)) +\n  geom_boxplot(fill = \"#D9E3E4\") + \n  labs(title = \"Age vs.\\nHealth Rating\") +\n  coord_flip()\n\np2 <- ggplot(data = nhanes_adult, aes(x = PhysActive, fill = HealthGen)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"Proportion\", \n       title = \"Physical Activity vs.\\nHealth Rating\")\n\np1 + p2\n```\n\n# Fitting a multinomial logistic regression\n\n## Model in R\n\nUse the `multinom_reg()` function with the `\"nnet\"` engine:\n\n```{r}\nhealth_fit <- multinom_reg() %>%\n  set_engine(\"nnet\") %>%\n  fit(HealthGen ~ Age + PhysActive, data = nhanes_adult)\n```\n\n## Model result\n\n```{r}\nhealth_fit\n```\n\n## Next steps\n\n::: question\nWhat function do we use to get the model summary, i.e., coefficient estimates.\n:::\n\n. . .\n\n```{r}\n#| error: true\n\ntidy(health_fit)\n```\n\n## Looking inside the result of `fit()`\n\n::: question\nWhat is the name of the dataset in the call?\nIs it right?\n:::\n\n```{r}\nhealth_fit$fit$call\n```\n\n## Repair, and get back on track\n\n```{r}\nhealth_fit <- repair_call(health_fit, data = nhanes_adult)\nhealth_fit$fit$call\ntidy(health_fit)\n```\n\n## Model output\n\n```{r}\ntidy(health_fit)\n```\n\n## Model output, with CI\n\n```{r}\ntidy(health_fit, conf.int = TRUE)\n```\n\n## Model output, with CI {.smaller}\n\n```{r}\n#| echo: false\ntidy(health_fit, conf.int = TRUE) %>%\n  kable(digits = 3)\n```\n\n## Fair vs. Excellent Health\n\nThe baseline category for the model is `Excellent`.\n\n. . .\n\nThe model equation for the log-odds a person rates themselves as having \"Fair\" health vs. \"Excellent\" is\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\n## Interpretations {.smaller}\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\nFor each additional year in age, the odds a person rates themselves as having fair health versus excellent health are expected to multiply by `r round(exp(0.003), 3)` (exp(0.003)), holding physical activity constant.\n\n. . .\n\nThe odds a person who does physical activity will rate themselves as having fair health versus excellent health are expected to be `r round(exp(-1.645 ),3)` (exp(-1.645)) times the odds for a person who doesn't do physical activity, holding age constant.\n\n## Interpretations\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\nThe odds a 0 year old person who doesn't do physical activity rates themselves as having fair health vs. excellent health are `r round(exp(0.915),3)` (exp(0.915)).\n\n. . .\n\n`r emo::ji(\"warning\")` **Need to mean-center age for the intercept to have a meaningful interpretation!**\n\n## Hypothesis test for $\\beta_{jk}$\n\nThe test of significance for the coefficient $\\beta_{jk}$ is\n\n**Hypotheses**: $H_0: \\beta_{jk} = 0 \\hspace{2mm} \\text{ vs } \\hspace{2mm} H_a: \\beta_{jk} \\neq 0$\n\n**Test Statistic**: $$z = \\frac{\\hat{\\beta}_{jk} - 0}{SE(\\hat{\\beta_{jk}})}$$\n\n**P-value**: $P(|Z| > |z|)$,\n\nwhere $Z \\sim N(0, 1)$, the Standard Normal distribution\n\n## Confidence interval for $\\beta_{jk}$\n\n-   We can calculate the **C% confidence interval** for $\\beta_{jk}$ using $\\hat{\\beta}_{jk} \\pm z^* SE(\\hat{\\beta}_{jk})$, where $z^*$ is calculated from the $N(0,1)$ distribution.\n\n-   We are $C\\%$ confident that for every one unit change in $x_{j}$, the odds of $y = k$ versus the baseline will multiply by a factor of $\\exp\\{\\hat{\\beta}_{jk} - z^* SE(\\hat{\\beta}_{jk})\\}$ to $\\exp\\{\\hat{\\beta}_{jk} + z^* SE(\\hat{\\beta}_{jk})\\}$, holding all else constant.\n\n## Interpreting CIs for $\\beta_{jk}$ {.smaller}\n\n```{r}\ntidy(health_fit, conf.int = TRUE) %>%\n  filter(y.level == \"Fair\") %>%\n  kable(digits = 3)\n```\n\n<br>\n\n. . .\n\nWe are 95% confident, that for each additional year in age, the odds a person rates themselves as having fair health versus excellent health will multiply by `r round(exp(-0.003), 3)` (exp(-0.003)) to `r round(exp(0.009), 3)` (exp(0.009)) , holding physical activity constant.\n\n## Interpreting CIs for $\\beta_{jk}$ {.smaller}\n\n```{r}\ntidy(health_fit, conf.int = TRUE) %>%\n  filter(y.level == \"Fair\") %>%\n  kable(digits = 3)\n```\n\n<br>\n\nWe are 95% confident that the odds a person who does physical activity will rate themselves as having fair health versus excellent health are `r round(exp(-1.856   ),3)` (exp(-1.856 )) to `r round(exp(-1.435),3)` (exp(-1.435)) times the odds for a person who doesn't do physical activity, holding age constant.\n\n## Recap\n\n-   Introduce multinomial logistic regression\n\n-   Interpret model coefficients\n\n-   Inference for a coefficient $\\beta_{jk}$\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-23.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Multinomial Logistic Regression (MultiLR)","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","transition":"fade","slideNumber":true,"chalkboard":true}}}}