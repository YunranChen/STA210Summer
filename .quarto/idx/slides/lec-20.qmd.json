{"title":"LR: Prediction / classification","markdown":{"yaml":{"title":"LR: Prediction / classification","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto","echo":true}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 8, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n\nlibrary(countdown)\n```\n\n# Welcome\n\n## Topics\n\n::: nonincremental\n-   Bulding predictive logistic regression models\n-   Sensitivity and specificity\n-   Making classification decisions\n:::\n\n## Computational setup\n\n```{r}\n#| echo: true\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n# Data\n\n## `openintro::email` {.smaller}\n\nThese data represent incoming emails for the first three months of 2012 for an email account.\n\n::: nonincremental\n-   Outcome: `spam` - Indicator for whether the email was spam.\n-   Predictors: `spam`, \\``to_multiple`, `from`, `cc`, `sent_email`, `time`, `image`, `attach`, `dollar`, `winner`, `inherit`, `viagra`, `password`, `num_char`, `line_breaks`, `format`, `re_subj`, `exclaim_subj`, `urgent_subj`, `exclaim_mess`, `number`.\n:::\n\nSee [here](http://openintrostat.github.io/openintro/reference/email.html) for more detailed information on the variables.\n\n## Training and testing split\n\n```{r}\n# Fix random numbers by setting the seed \n# Enables analysis to be reproducible when random numbers are used \nset.seed(1116)\n\n# Put 75% of the data into the training set \nemail_split <- initial_split(email)\n\n# Create data frames for the two sets\nemail_train <- training(email_split)\nemail_test  <- testing(email_split)\n```\n\n## Exploratory analysis\n\nThe sample is **unbalanced** with respect to `spam`.\n\n```{r}\n#| echo: false\n\nggplot(email_train, aes(x = spam)) + \n  geom_bar() +\n  labs(title = \"Distribution of spam in training data\")\n```\n\n## Reminder: Modeling workflow\n\n-   Create a recipe for feature engineering steps to be applied to the training data\n\n-   Fit the model to the training data after these steps have been applied\n\n-   Using the model estimates from the training data, predict outcomes for the test data\n\n-   Evaluate the performance of the model on the test data\n\n# Start with a recipe\n\n## Initiate a recipe {.smaller}\n\n```{r initiate-recipe, results=\"hide\"}\nemail_rec <- recipe(\n  spam ~ .,          # formula\n  data = email_train  # data to use for cataloging names and types of variables\n  )\nsummary(email_rec)\n```\n\n```{r echo=FALSE}\nsummary(email_rec) %>% print(n = 21)\n```\n\n## Remove certain variables\n\n```{r}\nemail_rec <- email_rec %>%\n  step_rm(from, sent_email)\n```\n\n```{r echo=FALSE}\nemail_rec\n```\n\n## Feature engineer date\n\n```{r}\nemail_rec <- email_rec %>%\n  step_date(time, features = c(\"dow\", \"month\")) %>%\n  step_rm(time)\n```\n\n```{r echo=FALSE}\nemail_rec\n```\n\n## Discretize numeric variables\n\n```{r}\nemail_rec <- email_rec %>%\n  step_cut(cc, attach, dollar, breaks = c(0, 1))\n```\n\n```{r echo=FALSE}\nemail_rec\n```\n\n## Create dummy variables\n\n```{r}\nemail_rec <- email_rec %>%\n  step_dummy(all_nominal(), -all_outcomes())\n```\n\n```{r echo=FALSE}\nemail_rec\n```\n\n## Remove zero variance variables\n\nVariables that contain only a single value\n\n```{r}\nemail_rec <- email_rec %>%\n  step_zv(all_predictors())\n```\n\n```{r echo=FALSE}\nemail_rec\n```\n\n## All in one place\n\n```{r}\nemail_rec <- recipe(spam ~ ., data = email_train) %>%\n  step_rm(from, sent_email) %>%\n  step_date(time, features = c(\"dow\", \"month\")) %>%               \n  step_rm(time) %>%\n  step_cut(cc, attach, dollar, breaks = c(0, 1)) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors())\n```\n\n# Build a workflow\n\n## Define model\n\n```{r}\nemail_spec <- logistic_reg() %>% \n  set_engine(\"glm\")\nemail_spec\n```\n\n## Define workflow {.smaller}\n\n**Remember:** Workflows bring together models and recipes so that they can be easily applied to both the training and test data.\n\n```{r}\nemail_wflow <- workflow() %>% \n  add_model(email_spec) %>% \n  add_recipe(email_rec)\n```\n\n```{r echo=FALSE}\nemail_wflow\n```\n\n## Fit model to training data {.smaller}\n\n```{r}\nemail_fit <- email_wflow %>% \n  fit(data = email_train)\n\ntidy(email_fit) %>% print(n = 31)\n```\n\n# Make predictions\n\n## Make predictions for test data\n\n```{r}\nemail_pred <- predict(email_fit, email_test, type = \"prob\") %>% \n  bind_cols(email_test) \nemail_pred\n```\n\n## A closer look at predictions\n\n::: question\nWhich of the following 10 emails will be misclassified?\n:::\n\n```{r}\nemail_pred %>%\n  arrange(desc(.pred_1)) %>%\n  select(contains(\"pred\"), spam)\n```\n\n# Sensitivity and specificity\n\n## False positive and negative {.smaller}\n\n|                              | Email is spam                 | Email is not spam             |\n|------------------------------|-------------------------------|-------------------------------|\n| Email classified as spam     | True positive                 | False positive (Type 1 error) |\n| Email classified as not spam | False negative (Type 2 error) | True negative                 |\n\n-   False negative rate = P(classified as not spam \\| Email spam) = FN / (TP + FN)\n\n-   False positive rate = P(classified as spam \\| Email not spam) = FP / (FP + TN)\n\n## Sensitivity and specificity {.smaller}\n\n|                              | Email is spam                     | Email is not spam                 |\n|------------------------------|-----------------------------------|-----------------------------------|\n| Email classified as spam     | True positive                     | False positive (**Type 1 error**) |\n| Email classified as not spam | False negative (**Type 2 error**) | True negative                     |\n\n-   Sensitivity = P(classified as spam \\| Email spam) = TP / (TP + FN)\n    -   Sensitivity = 1 − False negative rate\n-   Specificity = P(classified as not spam \\| Email not spam) = TN / (FP + TN)\n    -   Specificity = 1 − False positive rate\n\n. . .\n\n::: question\nIf you were designing a spam filter, would you want sensitivity and specificity to be high or low?\nWhat are the trade-offs associated with each decision?\n:::\n\n## Evaluate the performance\n\n**Receiver operating characteristic (ROC) curve**<sup>+</sup> which plot true positive rate vs. false positive rate (1 - specificity).\n\n::: aside\n<sup>+</sup> Originally developed for operators of military radar receivers, hence the name.\n:::\n\n::: columns\n::: {.column width=\"40%\"}\n```{r}\n#| label: roc-curve\n#| fig.show: hide\n\nemail_pred %>%\n  roc_curve(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  ) %>%\n  autoplot()\n```\n:::\n\n::: {.column width=\"60%\"}\n```{r}\n#| ref.label: roc-curve\n#| echo: false\n#| out.width: \"100%\"\n```\n:::\n:::\n\n## ROC curve, under the hood\n\n```{r}\nemail_pred %>%\n  roc_curve(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  )\n```\n\n## ROC curve\n\n```{r}\n#| echo: false\n\nemail_pred %>%\n  roc_curve(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  ) %>%\n  autoplot() +\n  annotate(\"point\", x = 0, y = 1, color = \"#5B888C\") +\n  annotate(\"point\", x = 0, y = 1, color = \"#5B888C\", size = 3, shape = \"circle open\") +\n  annotate(\n    \"label\", x = 0.02, y = 0.99, label = \"All spams classified as spam,\\nall non-spams classified as nonspam\", hjust = 0, color = \"#5B888C\", fontface = \"bold\", vjust = 1, fill = \"white\"\n  ) +\n  annotate(\"point\", x = 1, y = 0, color = \"#8F2D56\") +\n  annotate(\"point\", x = 1, y = 0, color = \"#8F2D56\", size = 3, shape = \"circle open\") +\n  annotate(\n    \"label\", x = 0.98, y = 0.01, label = \"All spams classified as non-spam,\\nall non-spams classified as spam\", hjust = 1, color = \"#8F2D56\", fontface = \"bold\", vjust = 0, fill = \"white\"\n  ) +\n  annotate(\n    \"segment\", color = \"#5b708c\", x = 0, y = 0, xend = 1, yend = 1, size = 2, alpha = 0.5\n  ) +\n  annotate(\n    \"label\", x = 0.58, y = 0.5, label = \"True positive rate\\n= false positive rate\", hjust = 0, color = \"#5b708c\", fontface = \"bold\", fill = \"white\"\n  )\n```\n\n## Evaluate the performance\n\n```{r}\n#| label: roc-auc\n\nemail_pred %>%\n  roc_auc(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  )\n```\n\n# Make decisions\n\n## Cutoff probability: 0.5 {.smaller}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.5**.\n\n```{r}\n#| ref.label: confusion-50\n#| echo: false\n```\n\n## Code\n\n```{r}\n#| label: confusion-50\n#| results: hide\n\ncutoff_prob <- 0.5\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) %>%\n  count(spam_pred, spam) %>%\n  pivot_wider(names_from = spam, values_from = n) %>%\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n## Confusion matrix\n\nCross-tabulation of observed and predicted classes:\n\n```{r}\nemail_pred %>%\n  mutate(spam_predicted = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0))) %>%\n  conf_mat(truth = spam, estimate = spam_predicted)\n```\n\n## Classification\n\n```{r}\n#| fig.asp: 0.6\n#| echo: false\n#| fig.width: 10\n\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    classification = if_else(spam == spam_pred, \"Correct classification\", \"Misclassification\")\n  ) %>%\n  ggplot(aes(x = .pred_1, y = spam,\n             color = classification, shape = classification)) +\n  geom_jitter(width = 0, alpha = 0.5, size = 2) +  geom_vline(xintercept = cutoff_prob, linetype = \"dashed\") +\n  scale_color_manual(values = c(\"#5B888C\", \"#8F2D56\")) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    color = NULL, shape = NULL,\n    x = \"Predicted probability (.pred_1)\",\n    y = \"Observed\"\n  ) +\n  annotate(\"label\",\n    x = cutoff_prob, y = 2.75,\n    label = paste0(\"Cutoff probability = \", cutoff_prob)\n  ) +\n  coord_cartesian(clip = \"off\")\n```\n\n## Cutoff probability: 0.25 {.smaller}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.25**.\n\n```{r}\n#| ref.label: confusion-25\n#| echo: false\n```\n\n## Code\n\n```{r confusion-25}\n#| label: confusion-25\n#| results: hide\n\ncutoff_prob <- 0.25\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) %>%\n  count(spam_pred, spam) %>%\n  pivot_wider(names_from = spam, values_from = n) %>%\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n## Classification\n\n```{r}\n#| fig.asp: 0.6\n#| echo: false\n#| fig.width: 10\n\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    classification = if_else(spam == spam_pred, \"Correct classification\", \"Misclassification\")\n  ) %>%\n  ggplot(aes(x = .pred_1, y = spam,\n             color = classification, shape = classification)) +\n  geom_jitter(width = 0, alpha = 0.5, size = 2) +\n  geom_vline(xintercept = cutoff_prob, linetype = \"dashed\") +\n  scale_color_manual(values = c(\"#5B888C\", \"#8F2D56\")) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    color = NULL, shape = NULL,\n    x = \"Predicted probability (.pred_1)\",\n    y = \"Observed\"\n  ) +\n  annotate(\"label\",\n    x = cutoff_prob, y = 2.75,\n    label = paste0(\"Cutoff probability = \", cutoff_prob)\n  ) +\n  coord_cartesian(clip = \"off\")\n```\n\n## Cutoff probability: 0.75 {.smaller}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.75**.\n\n```{r}\n#| ref.label: confusion-75\n#| echo: false\n```\n\n## Code\n\n```{r confusion-75}\n#| label: confusion-75\n#| results: hide\n\ncutoff_prob <- 0.75\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) %>%\n  count(spam_pred, spam) %>%\n  pivot_wider(names_from = spam, values_from = n) %>%\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n## Classification\n\n```{r}\n#| fig.asp: 0.6\n#| echo: false\n#| fig.width: 10\n\nemail_pred %>%\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    classification = if_else(spam == spam_pred, \"Correct classification\", \"Misclassification\")\n  ) %>%\n  ggplot(aes(x = .pred_1, y = spam, \n             color = classification, shape = classification)) +  geom_jitter(width = 0, alpha = 0.5, size = 2) +\n  geom_vline(xintercept = cutoff_prob, linetype = \"dashed\") +\n  scale_color_manual(values = c(\"#5B888C\", \"#8F2D56\")) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    color = NULL, shape = NULL,\n    x = \"Predicted probability (.pred_1)\",\n    y = \"Observed\"\n  ) +\n  annotate(\"label\",\n    x = cutoff_prob, y = 2.75,\n    label = paste0(\"Cutoff probability = \", cutoff_prob)\n  ) +\n  coord_cartesian(clip = \"off\")\n```\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-20.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"LR: Prediction / classification","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","transition":"fade","slideNumber":true,"chalkboard":true}}}}