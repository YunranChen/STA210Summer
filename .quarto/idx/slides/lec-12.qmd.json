{"title":"Feature engineering","markdown":{"yaml":{"title":"Feature engineering","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","multiplex":true,"transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto"}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 10, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n```\n\n# Welcome\n\n## Announcements\n\n::: nonincremental\n-   Check Sakai Gradebook to make sure all scores so far are accurate\n-   Any questions on topic selection for projects?\n-   Any feedback on time of my office hours?\n:::\n\n## Midterm evaluation summary\n\n*Live analysis...*\n\n## Topics\n\n::: nonincremental\n-   Review: Training and testing splits\n-   Feature engineering with recipes\n:::\n\n## Computational setup\n\n```{r}\n#| echo: true\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n# Introduction\n\n## The Office\n\n![](images/lec-12/the-office.jpeg)\n\n## Data\n\nThe data come from [data.world](https://data.world/anujjain7/the-office-imdb-ratings-dataset), by way of [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-03-17/readme.md)\n\n```{r}\n#| echo: true\n\noffice_ratings <- read_csv(here::here(\"slides\", \"data/office_ratings.csv\"))\noffice_ratings\n```\n\n## IMDB ratings\n\n```{r}\nggplot(office_ratings, aes(x = imdb_rating)) +\n  geom_histogram(binwidth = 0.25) +\n  labs(\n    title = \"The Office ratings\",\n    x = \"IMDB rating\"\n  )\n```\n\n## IMDB ratings vs. number of votes\n\n```{r}\n#| fig.asp: 0.5\n\noffice_ratings %>%\n  mutate(season = as_factor(season)) %>%\n  ggplot(aes(x = total_votes, y = imdb_rating, color = season)) +\n  geom_jitter(alpha = 0.7) +\n  labs(\n    title = \"The Office ratings\",\n    x = \"Total votes\",\n    y = \"IMDB rating\",\n    color = \"Season\"\n  ) +\n  theme(legend.position = c(0.9, 0.5)) +\n  scale_color_viridis_d()\n```\n\n## Outliers\n\n```{r}\n#| fig.asp: 0.5\n\nggplot(office_ratings, aes(x = total_votes, y = imdb_rating)) +\n  geom_jitter() +\n  gghighlight(total_votes > 4000, label_key = title) +\n  labs(\n    title = \"The Office ratings\",\n    x = \"Total votes\",\n    y = \"IMDB rating\"\n  )\n```\n\n## Aside...\n\nIf you like the [Dinner Party](https://www.imdb.com/title/tt1031477/) episode, I highly recommend this [\"oral history\" of the episode](https://www.rollingstone.com/tv/tv-features/that-one-night-the-oral-history-of-the-greatest-office-episode-ever-629472/) published on Rolling Stone magazine.\n\n## Rating vs. air date\n\n```{r}\noffice_ratings %>%\n  mutate(season = as_factor(season)) %>%\n  ggplot(aes(x = air_date, y = imdb_rating, \n             color = season, size = total_votes)) +\n  geom_point() +\n  labs(x = \"Air date\", y = \"IMDB rating\",\n       title = \"The Office Ratings\") +\n  scale_color_viridis_d()\n```\n\n## IMDB ratings vs. seasons\n\n```{r}\noffice_ratings %>%\n  mutate(season = as_factor(season)) %>%\n  ggplot(aes(x = season, y = imdb_rating, color = season)) +\n  geom_boxplot() +\n  geom_jitter() +\n  guides(color = FALSE) +\n  labs(\n    title = \"The Office ratings\",\n    x = \"Season\",\n    y = \"IMDB rating\"\n  ) +\n  scale_color_viridis_d()\n```\n\n# Modeling\n\n## Train / test\n\n**Step 1:** Create an initial split:\n\n```{r}\n#| echo: true\n\nset.seed(123)\noffice_split <- initial_split(office_ratings) # prop = 3/4 by default\n```\n\n. . .\n\n<br>\n\n**Step 2:** Save training data\n\n```{r}\n#| echo: true\n\noffice_train <- training(office_split)\ndim(office_train)\n```\n\n. . .\n\n<br>\n\n**Step 3:** Save testing data\n\n```{r}\n#| echo: true\n\noffice_test  <- testing(office_split)\ndim(office_test)\n```\n\n## Training data\n\n```{r}\n#| echo: true\n\noffice_train\n```\n\n## Feature engineering\n\n-   We prefer simple models when possible, but **parsimony** does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\n\n-   Variables that go into the model and how they are represented are just as critical to success of the model\n\n-   **Feature engineering** allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)\n\n## Feature engineering with dplyr\n\n```{r}\noptions(dplyr.print_max = 6, dplyr.print_min = 6)\n```\n\n```{r}\n#| echo: true\n\noffice_train %>%\n  mutate(\n    season = as_factor(season),\n    month = lubridate::month(air_date),\n    wday = lubridate::wday(air_date)\n  )\n```\n\n. . .\n\n::: question\nCan you identify any potential problems with this approach?\n:::\n\n```{r}\noptions(dplyr.print_max = 10, dplyr.print_min = 10)\n```\n\n## Modeling workflow, revisited\n\n-   Create a **recipe** for feature engineering steps to be applied to the training data\n\n-   Fit the model to the training data after these steps have been applied\n\n-   Using the model estimates from the training data, predict outcomes for the test data\n\n-   Evaluate the performance of the model on the test data\n\n# Building recipes\n\n## Initiate a recipe\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2|3\"\n\noffice_rec <- recipe(\n  imdb_rating ~ .,    # formula\n  data = office_train # data for cataloguing names and types of variables\n  )\n\noffice_rec\n```\n\n## Step 1: Alter roles\n\n`title` isn't a predictor, but we might want to keep it around as an ID\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  update_role(title, new_role = \"ID\")\n\noffice_rec\n```\n\n## Step 2: Add features\n\nNew features for day of week and month\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_date(air_date, features = c(\"dow\", \"month\"))\n\noffice_rec\n```\n\n## Step 3: Add more features {.smaller}\n\nIdentify holidays in `air_date`, then remove `air_date`\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2,3,4,5,6\"\n\noffice_rec <- office_rec %>%\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  )\n\noffice_rec\n```\n\n## Step 4: Convert numbers to factors {.smaller}\n\nConvert `season` to factor\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_num2factor(season, levels = as.character(1:9))\n\noffice_rec\n```\n\n## Step 5: Make dummy variables {.smaller}\n\nConvert all nominal (categorical) predictors to factors\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_dummy(all_nominal_predictors())\n\noffice_rec\n```\n\n## Step 6: Remove zero variance pred.s {.smaller}\n\nRemove all predictors that contain only a single value\n\n```{r}\n#| echo: true\n#| code-line-numbers: \"|2\"\n\noffice_rec <- office_rec %>%\n  step_zv(all_predictors())\n\noffice_rec\n```\n\n## Putting it altogether {.smaller}\n\n```{r}\n#| label: recipe-altogether\n#| echo: true\n#| results: hide\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  # make title's role ID\n  update_role(title, new_role = \"ID\") %>%\n  # extract day of week and month of air_date\n  step_date(air_date, features = c(\"dow\", \"month\")) %>%\n  # identify holidays and add indicators\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  ) %>%\n  # turn season into factor\n  step_num2factor(season, levels = as.character(1:9)) %>%\n  # make dummy variables\n  step_dummy(all_nominal_predictors()) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n```\n\n## Putting it altogether\n\n```{r}\n#| echo: true\n\noffice_rec\n```\n\n## Recap\n\n::: nonincremental\n-   Review: Training and testing splits\n-   Feature engineering with recipes\n:::"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-12.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"Feature engineering","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Çetinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","multiplex":true,"transition":"fade","slideNumber":true,"chalkboard":true}}}}