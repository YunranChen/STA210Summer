{"title":"MLR: Inference conditions + multicollinearity","markdown":{"yaml":{"title":"MLR: Inference conditions + multicollinearity","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","format":{"revealjs":{"theme":"slides.scss","transition":"fade","slide-number":true,"incremental":true,"chalkboard":true}},"editor":"visual","execute":{"freeze":"auto","echo":true}},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n\n# figure options\nknitr::opts_chunk$set(\n  fig.width = 10, fig.asp = 0.618, out.width = \"90%\",\n  fig.retina = 3, dpi = 300, fig.align = \"center\"\n)\n\nlibrary(countdown)\n```\n\n# Welcome\n\n## Topics\n\n-   Conditions for inference\n\n-   Multicollinearity\n\n## Computational setup\n\n```{r}\n#| warning: false\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)      # for tables\nlibrary(patchwork)  # for laying out plots\nlibrary(rms)        # for vif\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n\n## Data: `rail_trail` {.smaller}\n\n::: nonincremental\n-   The Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.\n-   Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n:::\n\n```{r}\nrail_trail <- read_csv(here::here(\"slides\", \"data/rail_trail.csv\"))\nrail_trail\n```\n\nSource: [Pioneer Valley Planning Commission](http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf) via the **mosaicData** package.\n\n## Variables {.smaller}\n\n**Outcome**:\n\n`volume` estimated number of trail users that day (number of breaks recorded)\n\n**Predictors**\n\n::: nonincremental\n-   `hightemp` daily high temperature (in degrees Fahrenheit)\n-   `avgtemp` average of daily low and daily high temperature (in degrees Fahrenheit)\n-   `season` one of \"Fall\", \"Spring\", or \"Summer\"\n-   `cloudcover` measure of cloud cover (in oktas)\n-   `precip` measure of precipitation (in inches)\n-   `day_type` one of \"weekday\" or \"weekend\"\n:::\n\n# Conditions for inference\n\n## Full model {.smaller}\n\nIncluding all available predictors\n\nFit:\n\n```{r}\nrt_full_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(volume ~ ., data = rail_trail)\n```\n\n. . .\n\nSummarize:\n\n```{r}\ntidy(rt_full_fit)\n```\n\n. . .\n\nAugment:\n\n```{r}\nrt_full_aug <- augment(rt_full_fit$fit)\n```\n\n## Model conditions\n\n1.  Linearity: There is a linear relationship between the response and predictor variables.\n\n2.  Constant Variance: The variability about the least squares line is generally constant.\n\n3.  Normality: The distribution of the residuals is approximately normal.\n\n4.  Independence: The residuals are independent from each other.\n\n## Residuals vs. predicted values\n\n```{r}\n#| label: main_res_pred\n\nggplot(data = rt_full_aug, aes(x = .fitted, y = .resid)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Predicted values\", y = \"Residuals\")\n```\n\n## Linearity: Residuals vs. predicted\n\n::: question\nDoes the linearity condition appear to be met?\n:::\n\n```{r}\n#| ref.label: main_res_pred\n#| echo: false\n```\n\n## Linearity: Residuals vs. predicted\n\nIf there is some pattern in the plot of residuals vs. predicted values, you can look at individual plots of residuals vs. each predictor to try to identify the issue.\n\n## Linearity: Residuals vs. each predictor\n\n```{r}\n#| fig.asp: 0.5\n#| echo: false\n\np1 <- ggplot(data = rt_full_aug, aes(x = hightemp, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\np2 <- ggplot(data = rt_full_aug, aes(x = avgtemp, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\np3 <- ggplot(data = rt_full_aug, aes(x = season, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\np4 <- ggplot(data = rt_full_aug, aes(x = cloudcover, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\np5 <- ggplot(data = rt_full_aug, aes(x = precip, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\np6 <- ggplot(data = rt_full_aug, aes(x = day_type, y = .resid)) +\n  geom_point(alpha = 0.5) + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\")\n\n(p1 + p2 + p3) / (p4 + p5 + p6)\n```\n\n## Checking linearity\n\n-   The plot of residuals vs. predicted shows a fan shaped pattern\n\n-   The plots of residuals vs. high and low temperature also shows a similar pattern and vs. precipitation does not show a random scatter\n\n-   The linearity condition is not satisfied.\n\n## Checking constant variance\n\n::: question\nDoes the constant variance condition appear to be satisfied?\n:::\n\n```{r}\n#| ref.label: main_res_pred\n#| echo: false\n```\n\n## Checking constant variance\n\n-   The vertical spread of the residuals is not constant across the plot.\n\n-   The constant variance condition is not satisfied.\n\n## Checking normality\n\n```{r}\n#| fig.asp: 0.8\n#| echo: false\n\nresid_hist <- ggplot(rt_full_aug, aes(x = .resid)) +\n  geom_histogram(binwidth = 50) +\n  labs(x = \"Residuals\")\n\nresid_box <- ggplot(rt_full_aug, aes(x = .resid)) +\n  geom_boxplot()\n\nresid_hist / resid_box\n```\n\n## Overlaying a density plot on a histogram\n\n::: appex\nðŸ“‹ [github.com/sta210-s22/ae-8-rail-trail](https://github.com/sta210-s22/ae-8-rail-trail)\n:::\n\n::: columns\n::: {.column width=\"30%\"}\n::: question\n**Ex 3.** Recreate the following visualization in R based on the results of the model.\n:::\n:::\n\n::: {.column width=\"70%\"}\n```{r}\n#| label: density\n#| echo: false\n#| out.width: \"100%\"\n\nggplot(rt_full_aug, aes(.resid)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 50) +\n  stat_function(\n    fun = dnorm, \n    args = list(mean = mean(rt_full_aug$.resid), sd = sd(rt_full_aug$.resid)), \n    lwd = 2, \n    color = \"red\"\n  )\n```\n:::\n:::\n\n## Checking independence\n\n-   We can often check the independence condition based on the context of the data and how the observations were collected.\n\n-   If the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected.\n\n-   If there is a grouping variable lurking in the background, check the residuals based on that grouping variable.\n\n## Checking independence\n\nResiduals vs. order of data collection:\n\n```{r}\nggplot(rt_full_aug, aes(y = .resid, x = 1:nrow(rt_full_aug))) +\n  geom_point() +\n  labs(x = \"Order of data collection\", y = \"Residuals\")\n```\n\n## Checking independence\n\nResiduals vs. predicted values by `season`:\n\n```{r}\n#| fig.asp: 0.5\n#| echo: false\n\np1 <- ggplot(rt_full_aug, aes(x = season, fill = season, y = .resid)) +\n  geom_boxplot(show.legend = FALSE) +\n  labs(x = \"Season\", y = \"Residuals\")\n\np2 <- ggplot(rt_full_aug, aes(x = .fitted, color = season, y = .resid)) +\n  geom_point(alpha = 0.5, show.legend = FALSE) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Predicted value\", y = \"Residuals\")\n\np1 + p2\n```\n\n## Checking independence\n\nResiduals vs. predicted values by `day_type`:\n\n```{r}\n#| fig.asp: 0.5\n#| echo: false\n\np1 <- ggplot(rt_full_aug, aes(x = day_type, fill = day_type, y = .resid)) +\n  geom_boxplot(show.legend = FALSE) +\n  labs(x = \"Dat type\", y = \"Residuals\")\n\np2 <- ggplot(rt_full_aug, aes(x = .fitted, color = day_type, y = .resid)) +\n  geom_point(alpha = 0.5, show.legend = FALSE) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Predicted value\", y = \"Residuals\")\n\np1 + p2\n```\n\n## Checking independence\n\nNo clear pattern in the residuals vs. order of data collection plot and the model predicts similarly for seasons and day types.\nIndependence condition appears to be satisfied, as far as we can evaluate it.\n\n# Multicollinearity\n\n## Why multicollinearity is a problem\n\n-   We can't include two variables that have a perfect linear association with each other\n\n-   If we did so, we could not find unique estimates for the model coefficients\n\n## Example {.smaller}\n\nSuppose the true population regression equation is $y = 3 + 4x$\n\n-   Suppose we try estimating that equation using a model with variables $x$ and $z = x/10$\n\n$$\n\\begin{aligned}\\hat{y}&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2z\\\\\n&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2\\frac{x}{10}\\\\\n&= \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x\n\\end{aligned}\n$$\n\n## Example {.smaller}\n\n$$\\hat{y} = \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x$$\n\n-   We can set $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ to any two numbers such that $\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10} = 4$\n\n-   Therefore, we are unable to choose the \"best\" combination of $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$\n\n## Why multicollinearity is a problem\n\n-   When we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate\n\n-   In other words, we lose precision in our estimates of the regression coefficients\n\n-   This impedes our ability to use the model for inference or prediction\n\n## Detecting Multicollinearity\n\nMulticollinearity may occur when... - There are very high correlations $(r > 0.9)$ among two or more predictor variables, especially when the sample size is small\n\n-   One (or more) predictor variables is an almost perfect linear combination of the others\n\n-   Include a quadratic in the model mean-centering the variable first\n\n-   Including interactions between two or more continuous variables\n\n## Detecting multicollinearity in the EDA\n\n-   Look at a correlation matrix of the predictor variables, including all indicator variables\n    -   Look out for values close to 1 or -1\n-   Look at a scatterplot matrix of the predictor variables\n    -   Look out for plots that show a relatively linear relationship\n\n## Detecting Multicollinearity (VIF)\n\n**Variance Inflation Factor (VIF)**: Measure of multicollinearity in the regression model\n\n$$VIF(\\hat{\\beta}_j) = \\frac{1}{1-R^2_{X_j|X_{-j}}}$$\n\nwhere $R^2_{X_j|X_{-j}}$ is the proportion of variation $X$ that is explained by the linear combination of the other explanatory variables in the model.\n\n## Detecting Multicollinearity (VIF)\n\nTypically $VIF > 10$ indicates concerning multicollinearity - Variables with similar values of VIF are typically the ones correlated with each other\n\n<br>\n\nUse the `vif()` function in the **rms** R package to calculate VIF\n\n## VIF For SAT Model\n\n```{r echo = T}\nvif(rt_full_fit$fit)\n```\n\n. . .\n\n`hightemp` and `avgtemp` are correlated.\nWe need to remove one of these variables and refit the model.\n\n## Model without `hightemp` {.smaller}\n\n```{r}\nm1 <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(volume ~ . - hightemp, data = rail_trail)\n  \nm1 %>%\n  tidy() %>%\n  kable(digits = 3)\n\nglance(m1) %>%\n  select(adj.r.squared, AIC, BIC)\n```\n\n## Model without `avgtemp`\n\n```{r}\nm2 <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(volume ~ . - avgtemp, data = rail_trail)\n  \nm2 %>%\n  tidy() %>%\n  kable(digits = 3)\n\nglance(m2) %>%\n  select(adj.r.squared, AIC, BIC)\n```\n\n## Choosing a model\n\nModel with **hightemp** removed:\n\n```{r}\n#| echo: false\n\nglance(m1) %>%\n  select(adj.r.squared, AIC, BIC) %>% kable(digits = 2)\n```\n\nModel with **avgtemp** removed:\n\n```{r echo = F}\n#| echo: false\n\nglance(m2) %>%\n  select(adj.r.squared, AIC, BIC) %>% kable(digits = 2)\n```\n\nBased on Adjusted $R^2$, AIC, and BIC, the model with **avgtemp** removed is a better fit.\nTherefore, we choose to remove **avgtemp** from the model and leave **hightemp** in the model to deal with the multicollinearity.\n\n## Recap\n\n-   Conditions for inference\n\n-   Multicollinearity\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"lec-17.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"0.9.345","auto-stretch":true,"editor":"visual","title":"MLR: Inference conditions + multicollinearity","subtitle":"STA 210 - Spring 2022","author":"Dr. Mine Ã‡etinkaya-Rundel","footer":"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)","logo":"images/logo.png","theme":"slides.scss","transition":"fade","slideNumber":true,"chalkboard":true}}}}