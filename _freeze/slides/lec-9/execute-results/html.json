{
  "hash": "d93065281b84762f1670e24f7a6a7829",
  "result": {
    "markdown": "---\ntitle: \"Model Diagnostics and Exam 1 Review\"\nsubtitle: \"STA 210 - Summer 2022\"\nauthor: \"Yunran Chen\"\nfooter:  \"[yunranchen.github.io/STA210Summer/](https://yunranchen.github.io/STA210Summer/)\"\nlogo: \"images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: true\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n## Announcements\n\n-   Exam 1 opens today at 1:00 pm and ends on Monday, May 23 at 11:59pm.\n\n## Feedback from submissions so far\n\n-   You must submit a PDF (not HTML) to Gradescope\n-   You must tag your pages when you upload to Gradescope -- if you don't know how to do this, please ask well before the deadline!\n-   You must not refer to keys distributed in previous semesters of the course -- much of what we're doing is different and some of it is the same. If you need help, please ask!\n\n## Exam 1\n\n-   Instructions can be found at website\n-   Covers everything we've done so far\n-   Any clarification questions for the exam?\n    -   Post on Sakai Conversations, post to \"Instructors in this site\"\n\n## Interpretation on CI\n\nWe are 95% confident that, as xx increase by 1 unit, the model predicts xx increase/decrease \\[,\\] on average.\n\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between XX and XX.\n\n\n## Tips on R programming\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntest <- tibble(a=1,b=2)\ntest\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n      a     b\n  <dbl> <dbl>\n1     1     2\n```\n:::\n:::\n\n\nThe test values are  1 and 2.\n\n\n## Outliers and influential points\n\n## Outliers\n\n-   Boxplot\n-   Standard residuals\n\n![](images/boxplot.png)\n\n## Identifying influential points\n\n-   Leverage\n-   Standardized residuals\n-   Cook's Distance\n\n\n::: {.cell}\n\n:::\n\n\n\n## Influential Point\n\nAn observation is influential if removing it substantially changes the coefficients of the regression model\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n## Influential points\n\n-   Influential points have a large impact on the coefficients and standard errors used for inference\n\n\n-   These points can sometimes be identified in a scatterplot if there is only one predictor variable\n    -   This is often not the case when there are multiple predictors\n\n\n-   We will use measures to quantify an individual observation's influence on the regression model\n    -   **leverage**, **standardized residuals**, and **Cook's distance**\n\n\n## Model diagnostics in R\n\nUse the `augment` function to output the model diagnostics (along with the predicted values and residuals)\n\n-   response and predictor variables in the model\n-   `.fitted`: predicted values\n-   `.se.fit`: standard errors of predicted values\n-   `.resid`: residuals\n-   `.hat`: leverage\n-   `.sigma`: estimate of residual standard deviation when the corresponding observation is dropped from model\n-   `.cooksd`: Cook's distance\n-   `.std.resid`: standardized residuals\n\n\n## Example: Average SAT scores by state\n\n-   This data set contains the average SAT score (out of 1600) and other variables that may be associated with SAT performance for each of the 50 U.S. states. The data is based on test takers for the 1982 exam.\n\n-   **Response** - .vocab\\[`SAT`\\]: average total SAT score\n\n-   **Predictor** - .vocab\\[`Public`\\]: percentage of test-takers who attended public high schools\n\n## .footnote\\[Data comes from `case1201` data set in the `Sleuth3` package\\]\n\n## Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsat_scores <- Sleuth3::case1201\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsat_model <- lm(SAT ~ Public, data = sat_scores)\ntidy(sat_model) %>%\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 994.971 </td>\n   <td style=\"text-align:right;\"> 84.807 </td>\n   <td style=\"text-align:right;\"> 11.732 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Public </td>\n   <td style=\"text-align:right;\"> -0.579 </td>\n   <td style=\"text-align:right;\"> 1.037 </td>\n   <td style=\"text-align:right;\"> -0.559 </td>\n   <td style=\"text-align:right;\"> 0.579 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## SAT: Augmented Data\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nRows: 50\nColumns: 9\n$ SAT        <int> 1088, 1075, 1068, 1045, 1045, 1033, 1028, 1022, 1017, 1011,…\n$ Public     <dbl> 87.8, 86.2, 88.3, 83.9, 83.6, 93.7, 78.3, 75.2, 97.0, 77.3,…\n$ .fitted    <dbl> 944.1198, 945.0465, 943.8302, 946.3786, 946.5523, 940.7027,…\n$ .resid     <dbl> 143.880224, 129.953547, 124.169810, 98.621450, 98.447698, 9…\n$ .hat       <dbl> 0.02918707, 0.02527061, 0.03063269, 0.02153481, 0.02121224,…\n$ .sigma     <dbl> 68.89683, 69.51144, 69.72849, 70.63271, 70.63847, 70.77489,…\n$ .cooksd    <dbl> 0.0629494764, 0.0441056591, 0.0493526954, 0.0214814500, 0.0…\n$ .std.resid <dbl> 2.0463672, 1.8445751, 1.7673480, 1.3971689, 1.3944776, 1.32…\n$ obs_num    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n```\n:::\n:::\n\n\n## Leverage\n\n-   Leverage: measure of the distance between an observation's values of the predictor variables and the average values of the predictor variables for the entire data set\n\n-   An observation has **high leverage** if its combination of values for the predictor variables is very far from the typical combination of values in the data\n\n-   Observations with high leverage should be considered as *potential* influential points\n\n\n## Calculating leverage\n\nSimple Regression: leverage of the $i^{th}$ observation  $$h_i =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}$$\n\n-   *Note*: Leverage only depends on values of the predictor variable(s)\n\n## High Leverage\n\n-   The sum of the leverages for all points is $p + 1$ \n  - $p$ is the number of predictors \n  - In the case of SLR $\\sum_{i=1}^n h_i = 2$\n\n-   The \"typical\" leverage is $\\frac{(p+1)}{n}$\n\n-   An observation has **high leverage** if $$h_i > \\frac{2(p+1)}{n}$$\n\n\n## High Leverage\n\nIf there is point with high leverage, ask\n\n-   Is there a data entry error?\n\n-   Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n\n-   Is this observation impacting the estimates of the model coefficients, especially for interactions?\n\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures.\n\n\n## SAT: Leverage\n\n\n## Observations with high leverage\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08\n```\n:::\n\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n    SAT Public\n  <int>  <dbl>\n1   999   61.2\n2   975   44.8\n```\n:::\n:::\n\n\n Why do you think these observations have high leverage?\n\n\n## Let's dig into the data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Standardized residuals\n\n-   What is the best way to identify outliers (points that don't fit the pattern from the regression line)?\n\n-   Look for points that have large residuals\n\n-   We want a common scale, so we can more easily identify \"large\" residuals\n\n-   We will look at each residual divided by its standard error\n\n\n## Standardized residuals\n\n\n $$std.res_i = \\frac{y_i - \\hat{y}_i}{\\hat{\\sigma}_\\epsilon\\sqrt{1-h_i}}$$\n\n-   Standardized residuals are produced by `augment` in the column `.std.resid`\n\n\n## Standardized residuals\n\nObservations with high leverage tend to have low values of standardized residuals because they pull the regression line towards them\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n## Using standardized residuals\n\nObservations that have standardized residuals of large magnitude are outliers, since they don't fit the pattern determined by the regression model\n\nAn observation is a *potential outlier* if its standardized residual is beyond $\\pm 3$.\n\nMake residual plots with standardized residuals to make it easier to identify outliers\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Motivating Cook's Distance\n\nAn observation's influence on the regression line depends on\n\n-   How close it lies to the general trend of the data - (Standardized residual)\n\n-   Its leverage - $h_i$\n\n\nCook's Distance is a statistic that includes both of these components to measure an observation's overall impact on the model\n\n\n## Cook's Distance\n\n**Cook's distance for the** $i^{th}$ observation\n\n\nAn observation with large $D_i$ is said to have a strong influence on the predicted values\n\n\nAn observation with \n\n-   $D_i > 0.5$ is **moderately influential** \n-   $D_i > 1$ is **very influential**\n\n## Cook's Distance\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-9_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n## Using these measures\n\n-   Standardized residuals, leverage, and Cook's Distance should all be examined together\n\n-   Examine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model.\n\n\n## What to do with outliers/influential points?\n\nIt is OK to drop an observation based on the predictor variables if...\n\n-   It is meaningful to drop the observation given the context of the problem\n\n-   You intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions\n\n------------------------------------------------------------------------\n\n## What to do with outliers/influential points?\n\nIt is not OK to drop an observation based on the response variable\n\n-   These are legitimate observations and should be in the model\n\n-   You can try transformations or increasing the sample size by collecting more data\n\n--\n\nIn either instance, you can try building the model with and without the outliers/influential observations\n\n\n## Application Exercise\n\n::: appex\n📋 [github.com/STA210-Summer22/ae-4](https://github.com/STA210-Summer22?q=ae-4&type=all&language=&sort=)\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}